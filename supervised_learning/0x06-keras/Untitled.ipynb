{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cp 1-input.py 2-optimize.py\n",
    "!chmod +x *.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_197 (Dense)            (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dropout_104 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_105 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[<tf.Tensor 'kernel/Regularizer_149/add:0' shape=() dtype=float32>, <tf.Tensor 'kernel/Regularizer_150/add:0' shape=() dtype=float32>, <tf.Tensor 'kernel/Regularizer_151/add:0' shape=() dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "#build_model = __import__('0-sequential').build_model\n",
    "\"\"\" doc \"\"\"\n",
    "import tensorflow.keras as K\n",
    "\n",
    "\n",
    "def build_model(nx, layers, activations, lambtha, keep_prob):\n",
    "    \"\"\" doc \"\"\"\n",
    "    model = K.Sequential()\n",
    "    for i in range(len(layers)):\n",
    "        init = K.initializers.VarianceScaling(mode=\"fan_avg\")\n",
    "        # freg = K.layers.ActivityRegularization(l2=lambtha)\n",
    "        freg = K.regularizers.l2(lambtha)\n",
    "        layer = K.layers.Dense(layers[i], input_dim=nx,\n",
    "                               activation=activations[i],\n",
    "                               kernel_initializer=init,\n",
    "                               kernel_regularizer=freg)\n",
    "        model.add(layer)\n",
    "        if i != len(layers)-1:\n",
    "            dropped = K.layers.Dropout(rate=1-keep_prob)\n",
    "            model.add(dropped)\n",
    "    return (model)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    network = build_model(784, [256, 256, 10], ['tanh', 'tanh', 'softmax'], 0.001, 0.95)\n",
    "    network.summary()\n",
    "    print(network.losses)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[<tf.Tensor 'dense/kernel/Regularizer/add:0' shape=() dtype=float32>, <tf.Tensor 'dense_1/kernel/Regularizer/add:0' shape=() dtype=float32>, <tf.Tensor 'dense_2/kernel/Regularizer/add:0' shape=() dtype=float32>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_103 (InputLayer)       (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_409 (Dense)            (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dropout_309 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_410 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_310 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_411 (Dense)            (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[<tf.Tensor 'kernel/Regularizer_276/add:0' shape=() dtype=float32>, <tf.Tensor 'kernel/Regularizer_277/add:0' shape=() dtype=float32>, <tf.Tensor 'kernel/Regularizer_278/add:0' shape=() dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "def build_model(nx, layers, activations, lambtha, keep_prob):\n",
    "    inputs = K.Input(shape=(nx,))\n",
    "    freg = K.regularizers.l2(lambtha)\n",
    "    x = K.layers.Dense(layers[0], activation=activations[0],\n",
    "                           kernel_regularizer=freg)(inputs)\n",
    "    for i in range(1, len(layers)):\n",
    "        x = K.layers.Dropout(rate=1-keep_prob)(x)\n",
    "        x = K.layers.Dense(layers[i], activation=activations[i],\n",
    "                           kernel_regularizer=freg)(x)\n",
    "        \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "    return (model)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    network = build_model(784, [256, 256, 10], ['tanh', 'tanh', 'softmax'], 0.001, 0.95)\n",
    "    network.summary()\n",
    "    print(network.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output \"dense_444\" missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to \"dense_444\".\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "('Expected `target_tensors` to be a list or dict, but got:', 'categorical_crossentropy')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-203-a5b63d2fee0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'tanh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tanh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'softmax'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0moptimize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-203-a5b63d2fee0c>\u001b[0m in \u001b[0;36moptimize_model\u001b[0;34m(network, alpha, beta1, beta2)\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0mweighted_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mtarget_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mdistribute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                     )\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/training/checkpointable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m       \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         raise TypeError('Expected `target_tensors` to be '\n\u001b[0;32m--> 570\u001b[0;31m                         'a list or dict, but got:', target_tensors)\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ('Expected `target_tensors` to be a list or dict, but got:', 'categorical_crossentropy')"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "build_model = __import__('1-input').build_model\n",
    "# optimize_model = __import__('2-optimize').optimize_model\n",
    "def optimize_model(network, alpha, beta1, beta2):\n",
    "    \"\"\" doc \"\"\"\n",
    "    optimizer = K.optimizers.Adam(alpha, beta1, beta2)\n",
    "    network.compile(optimizer,\n",
    "                    loss=\"\",\n",
    "                    metrics=None,\n",
    "                    loss_weights=None,\n",
    "                    sample_weight_mode=None,\n",
    "                    weighted_metrics=None,\n",
    "                    target_tensors=None,\n",
    "                    distribute=None,\n",
    "                    )\n",
    "    return None\n",
    "if __name__ == '__main__':\n",
    "    model = build_model(784, [256, 256, 10], ['tanh', 'tanh', 'softmax'], 0.001, 0.95)\n",
    "    optimize_model(model, 0.01, 0.99, 0.9)\n",
    "    print(model.loss)\n",
    "    print(model.metrics)\n",
    "    opt = model.optimizer\n",
    "    print(opt.__class__)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print(sess.run((opt.lr, opt.beta_1, opt.beta_2))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
