{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cp 3-one_hot.py 4-train.py\n",
    "!chmod +x *.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_197 (Dense)            (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dropout_104 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_105 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[<tf.Tensor 'kernel/Regularizer_149/add:0' shape=() dtype=float32>, <tf.Tensor 'kernel/Regularizer_150/add:0' shape=() dtype=float32>, <tf.Tensor 'kernel/Regularizer_151/add:0' shape=() dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "#build_model = __import__('0-sequential').build_model\n",
    "\"\"\" doc \"\"\"\n",
    "import tensorflow.keras as K\n",
    "\n",
    "\n",
    "def build_model(nx, layers, activations, lambtha, keep_prob):\n",
    "    \"\"\" doc \"\"\"\n",
    "    model = K.Sequential()\n",
    "    for i in range(len(layers)):\n",
    "        init = K.initializers.VarianceScaling(mode=\"fan_avg\")\n",
    "        # freg = K.layers.ActivityRegularization(l2=lambtha)\n",
    "        freg = K.regularizers.l2(lambtha)\n",
    "        layer = K.layers.Dense(layers[i], input_dim=nx,\n",
    "                               activation=activations[i],\n",
    "                               kernel_initializer=init,\n",
    "                               kernel_regularizer=freg)\n",
    "        model.add(layer)\n",
    "        if i != len(layers)-1:\n",
    "            dropped = K.layers.Dropout(rate=1-keep_prob)\n",
    "            model.add(dropped)\n",
    "    return (model)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    network = build_model(784, [256, 256, 10], ['tanh', 'tanh', 'softmax'], 0.001, 0.95)\n",
    "    network.summary()\n",
    "    print(network.losses)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[<tf.Tensor 'dense/kernel/Regularizer/add:0' shape=() dtype=float32>, <tf.Tensor 'dense_1/kernel/Regularizer/add:0' shape=() dtype=float32>, <tf.Tensor 'dense_2/kernel/Regularizer/add:0' shape=() dtype=float32>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_103 (InputLayer)       (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_409 (Dense)            (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dropout_309 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_410 (Dense)            (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_310 (Dropout)        (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_411 (Dense)            (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[<tf.Tensor 'kernel/Regularizer_276/add:0' shape=() dtype=float32>, <tf.Tensor 'kernel/Regularizer_277/add:0' shape=() dtype=float32>, <tf.Tensor 'kernel/Regularizer_278/add:0' shape=() dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "def build_model(nx, layers, activations, lambtha, keep_prob):\n",
    "    inputs = K.Input(shape=(nx,))\n",
    "    freg = K.regularizers.l2(lambtha)\n",
    "    x = K.layers.Dense(layers[0], activation=activations[0],\n",
    "                           kernel_regularizer=freg)(inputs)\n",
    "    for i in range(1, len(layers)):\n",
    "        x = K.layers.Dropout(rate=1-keep_prob)(x)\n",
    "        x = K.layers.Dense(layers[i], activation=activations[i],\n",
    "                           kernel_regularizer=freg)(x)\n",
    "        \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "    return (model)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    network = build_model(784, [256, 256, 10], ['tanh', 'tanh', 'softmax'], 0.001, 0.95)\n",
    "    network.summary()\n",
    "    print(network.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical_crossentropy\n",
      "['accuracy']\n",
      "<class 'tensorflow.python.keras.optimizers.Adam'>\n",
      "(0.01, 0.99, 0.9)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "build_model = __import__('1-input').build_model\n",
    "# optimize_model = __import__('2-optimize').optimize_model\n",
    "def optimize_model(network, alpha, beta1, beta2):\n",
    "    \"\"\" doc \"\"\"\n",
    "    optimizer = K.optimizers.Adam(alpha, beta1, beta2)\n",
    "    network.compile(optimizer,\n",
    "                    loss=\"categorical_crossentropy\",\n",
    "                    metrics=['accuracy'])\n",
    "    return None\n",
    "if __name__ == '__main__':\n",
    "    model = build_model(784, [256, 256, 10], ['tanh', 'tanh', 'softmax'], 0.001, 0.95)\n",
    "    optimize_model(model, 0.01, 0.99, 0.9)\n",
    "    print(model.loss)\n",
    "    print(model.metrics)\n",
    "    opt = model.optimizer\n",
    "    print(opt.__class__)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print(sess.run((opt.lr, opt.beta_1, opt.beta_2))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import numpy as np\n",
    "#one_hot = __import__('3-one_hot').one_hot\n",
    "def one_hot(labels, classes=None):\n",
    "    \"\"\" doc \"\"\"\n",
    "    return K.utils.to_categorical(labels, classes)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    labels = np.load('../data/MNIST.npz')['Y_train'][:10]\n",
    "    print(labels)\n",
    "    print(one_hot(labels))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 15s 300us/step - loss: 0.3341 - acc: 0.9182\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 0.1772 - acc: 0.9649\n",
      "Epoch 3/5\n",
      "42240/50000 [========================>.....] - ETA: 2s - loss: 0.1427 - acc: 0.9752"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "build_model = __import__('1-input').build_model\n",
    "optimize_model = __import__('2-optimize').optimize_model\n",
    "one_hot = __import__('3-one_hot').one_hot\n",
    "#train_model = __import__('4-train').train_model\n",
    "\n",
    "def train_model(network, data, labels, batch_size,\n",
    "                epochs, verbose=True, shuffle=False):\n",
    "    \"\"\" doc \"\"\"\n",
    "    if verbose == True:\n",
    "        verbose = 1\n",
    "    else:\n",
    "        verbose = 0\n",
    "    return network.fit(data, labels,\n",
    "                       batch_size=batch_size,\n",
    "                       epochs=epochs,\n",
    "                       verbose=verbose,\n",
    "                       shuffle=shuffle)\n",
    "if __name__ == '__main__':\n",
    "    datasets = np.load('../data/MNIST.npz')\n",
    "    X_train = datasets['X_train']\n",
    "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "    Y_train = datasets['Y_train']\n",
    "    Y_train_oh = one_hot(Y_train)\n",
    "\n",
    "    np.random.seed(0)\n",
    "    tf.set_random_seed(0)\n",
    "    lambtha = 0.0001\n",
    "    keep_prob = 0.95\n",
    "    network = build_model(784, [256, 256, 10], ['relu', 'relu', 'softmax'], lambtha, keep_prob)\n",
    "    alpha = 0.001\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    optimize_model(network, alpha, beta1, beta2)\n",
    "    batch_size = 64\n",
    "    epochs = 5\n",
    "    train_model(network, X_train, Y_train_oh, batch_size, epochs)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Epoch 1/5\n",
    "50000/50000 [==============================] - 20s 399us/step - loss: 0.3307 - acc: 0.9185\n",
    "Epoch 2/5\n",
    "50000/50000 [==============================] - 10s 193us/step - loss: 0.1751 - acc: 0.9651\n",
    "Epoch 3/5\n",
    "50000/50000 [==============================] - 9s 184us/step - loss: 0.1425 - acc: 0.9751\n",
    "Epoch 4/5\n",
    "50000/50000 [==============================] - 10s 197us/step - loss: 0.1253 - acc: 0.9802\n",
    "Epoch 5/5\n",
    "50000/50000 [==============================] - 10s 195us/step - loss: 0.1159 - acc: 0.9828"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
