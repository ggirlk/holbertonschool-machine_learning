{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!touch 7-densenet121.py | chmod +x *.py\n",
    "#!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 224, 224, 96) 384         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 224, 224, 16) 64          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 224, 224, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 224, 224, 64) 256         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 224, 224, 128 110720      conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 224, 224, 32) 12832       conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 224, 224, 32) 128         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 224, 224, 256 0           conv2d[0][0]                     \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 124,384\n",
      "Trainable params: 124,384\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import tensorflow.keras as K\n",
    "#inception_block = __import__('0-inception_block').inception_block\n",
    "def inception_block(A_prev, filters):\n",
    "    \"\"\" doc \"\"\"\n",
    "    MaxPooling2D = K.layers.MaxPooling2D\n",
    "    Conv2D = K.layers.Conv2D\n",
    "    Concatenate = K.layers.Concatenate()\n",
    "    \n",
    "    F1, F3R, F3, F5R, F5, FPP = filters\n",
    "    \n",
    "    layer1x1_0 = Conv2D(F1, 1, activation='relu')(A_prev) #\n",
    "    \n",
    "    layer1x1_1 = Conv2D(F3R, 1, padding='same', activation='relu')(A_prev)\n",
    "    \n",
    "    layer3x3 = Conv2D(F3, 3, padding='same', activation='relu')(layer1x1_1) #\n",
    "    \n",
    "    layer1x1_2 = Conv2D(F5R, 1, padding='same', activation='relu')(A_prev)\n",
    "    \n",
    "    layer5x5 = Conv2D(F5, 5, padding='same',  activation='relu')(layer1x1_2) #\n",
    "    \n",
    "    layerMax = MaxPooling2D(1)(A_prev)\n",
    "    \n",
    "    layer1x1_3 = Conv2D(FPP, 1, padding='same', activation='relu')(layerMax) #\n",
    "    \n",
    "    layer_out = Concatenate([layer1x1_0, layer3x3, layer5x5, layer1x1_3])\n",
    "    return layer_out\n",
    "if __name__ == '__main__':\n",
    "    X = K.Input(shape=(224, 224, 3))\n",
    "    Y = inception_block(X, [64, 96, 128, 16, 32, 32])\n",
    "    model = K.models.Model(inputs=X, outputs=Y)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " [(None, 224, 224, 64), (None, 222, 222, 128), (None, 220, 220, 32), (None, 224, 224, 32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# one by one from the table\n",
    "def inception_network():\n",
    "    \"\"\" doc \"\"\"\n",
    "    MaxPooling2D = K.layers.MaxPooling2D\n",
    "    AveragePooling2D = K.layers.AveragePooling2D\n",
    "    Conv2D = K.layers.Conv2D\n",
    "    Dropout = K.layers.Dropout(rate=0.6)\n",
    "    Dense = K.layers.Dense\n",
    "    X = K.Input(shape=(224, 224, 3))\n",
    "    \n",
    "    layer7x7 = Conv2D(64, 7, 2, padding='same',  activation='relu')(X)\n",
    "    layerMax = MaxPooling2D(3, 2, padding='same')(layer7x7)\n",
    "    \n",
    "    layer3x3 = Conv2D(64, 1, 1,  activation='relu')(layerMax)\n",
    "    layer3x3 = Conv2D(192, 3, 1, padding='same',  activation='relu')(layer3x3)\n",
    "    layerMax_2 = MaxPooling2D(3, 2, padding='same')(layer3x3)\n",
    "\n",
    "    inception = inception_block(layerMax_2, [64, 96, 128, 16, 32, 32])\n",
    "    inception = inception_block(inception, [128, 128, 192, 32, 96, 64])\n",
    "    \n",
    "    layerMax_2 = MaxPooling2D(3, 2, padding='same')(inception)\n",
    "    inception = inception_block(layerMax_2, [192, 96, 208, 16, 48, 64])\n",
    "    inception = inception_block(inception, [160, 112, 224, 24, 64, 64])\n",
    "    inception = inception_block(inception, [128, 128, 256, 24, 64, 64])\n",
    "    inception = inception_block(inception, [112, 144, 288, 32, 64, 64])\n",
    "    inception = inception_block(inception, [256, 160, 320, 32, 128, 128])\n",
    "    layerMax_2 = MaxPooling2D(3, 2, padding='same')(inception)\n",
    "    inception = inception_block(layerMax_2, [256, 160, 320, 32, 128, 128])\n",
    "    inception = inception_block(inception, [384, 192, 384, 48, 128, 128])\n",
    "    layerAVG_2 = AveragePooling2D(7, 1)(inception)\n",
    "    dropped = Dropout(layerAVG_2)\n",
    "    # dropped = Dense(1000, activation=\"relu\")(dropped)\n",
    "    Y = Dense(1000, activation=\"softmax\")(dropped)\n",
    "\n",
    "    model = K.Model(inputs=X, outputs=Y)\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = inception_network()\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 224, 224, 256 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 224, 224, 64) 16448       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 224, 224, 64) 256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 224, 224, 64) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 224, 224, 64) 36928       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 224, 224, 64) 256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 224, 224, 64) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 224, 224, 256 16640       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 224, 224, 256 1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 224, 224, 256 0           batch_normalization_8[0][0]      \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 224, 224, 256 0           add_2[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 71,552\n",
      "Trainable params: 70,784\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def identity_block(A_prev, filters):\n",
    "    \"\"\" doc \"\"\"\n",
    "    Conv2D = K.layers.Conv2D\n",
    "    BatchNorm = K.layers.BatchNormalization\n",
    "    Activation = K.layers.Activation\n",
    "    Add = K.layers.Add\n",
    "    F11, F3, F12 = filters\n",
    "    layer1x1 = Conv2D(F11, 1, padding='same', kernel_initializer='he_normal')(A_prev)\n",
    "    layer1x1 = BatchNorm()(layer1x1)\n",
    "    layer1x1 = Activation('relu')(layer1x1)\n",
    "\n",
    "    layer3x3 = Conv2D(F3, 3, padding='same', kernel_initializer='he_normal')(layer1x1)\n",
    "    layer3x3 = BatchNorm()(layer3x3)\n",
    "    layer3x3 = Activation('relu')(layer3x3)\n",
    "\n",
    "    layer1x1 = Conv2D(F12, 1, padding='same', kernel_initializer='he_normal')(layer3x3)\n",
    "    layer1x1 = BatchNorm()(layer1x1)\n",
    "\n",
    "    layer_out = Add()([layer1x1, A_prev])\n",
    "    layer_out = Activation('relu')(layer_out)\n",
    "\n",
    "    return layer_out\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X = K.Input(shape=(224, 224, 256))\n",
    "    Y = identity_block(X, [64, 64, 256])\n",
    "    model = K.models.Model(inputs=X, outputs=Y)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_29 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1397 (Conv2D)            (None, 112, 112, 64) 256         input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1397 (Batch (None, 112, 112, 64) 256         conv2d_1397[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1291 (Activation)    (None, 112, 112, 64) 0           batch_normalization_1397[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1398 (Conv2D)            (None, 112, 112, 64) 36928       activation_1291[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1398 (Batch (None, 112, 112, 64) 256         conv2d_1398[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1292 (Activation)    (None, 112, 112, 64) 0           batch_normalization_1398[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1399 (Conv2D)            (None, 112, 112, 256 16640       activation_1292[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1400 (Conv2D)            (None, 112, 112, 256 1024        input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1399 (Batch (None, 112, 112, 256 1024        conv2d_1399[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1400 (Batch (None, 112, 112, 256 1024        conv2d_1400[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_418 (Add)                   (None, 112, 112, 256 0           batch_normalization_1399[0][0]   \n",
      "                                                                 batch_normalization_1400[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1293 (Activation)    (None, 112, 112, 256 0           add_418[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 57,408\n",
      "Trainable params: 56,128\n",
      "Non-trainable params: 1,280\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "projection_block = __import__('3-projection_block').projection_block\n",
    "\n",
    "def projection_block(A_prev, filters, s=2):\n",
    "    \"\"\" doc \"\"\"\n",
    "    Conv2D = K.layers.Conv2D\n",
    "    BatchNorm = K.layers.BatchNormalization\n",
    "    Activation = K.layers.Activation\n",
    "    Add = K.layers.Add\n",
    "    F11, F3, F12 = filters\n",
    "\n",
    "    layer1x1 = Conv2D(F11, 1, s, padding='same',\n",
    "                      kernel_initializer='he_normal')(A_prev)\n",
    "    layer1x1 = BatchNorm()(layer1x1)\n",
    "    layer1x1 = Activation('relu')(layer1x1)\n",
    "\n",
    "    layer3x3 = Conv2D(F3, 3, padding='same',\n",
    "                      kernel_initializer='he_normal')(layer1x1)\n",
    "    layer3x3 = BatchNorm()(layer3x3)\n",
    "    layer3x3 = Activation('relu')(layer3x3)\n",
    "\n",
    "    layer1x1 = Conv2D(F12, 1, padding='same',\n",
    "                      kernel_initializer='he_normal')(layer3x3)\n",
    "    layer1x1 = BatchNorm()(layer1x1)  #\n",
    "    \n",
    "    layer1x1_s = Conv2D(F12, 1, s,\n",
    "                      kernel_initializer='he_normal')(A_prev)\n",
    "    layer1x1_s = BatchNorm()(layer1x1_s)  #\n",
    "\n",
    "    layer_out = Add()([layer1x1, layer1x1_s])\n",
    "    layer_out = Activation('relu')(layer_out)\n",
    "\n",
    "    return layer_out\n",
    "if __name__ == '__main__':\n",
    "    X = K.Input(shape=(224, 224, 3))\n",
    "    Y = projection_block(X, [64, 64, 256])\n",
    "    model = K.models.Model(inputs=X, outputs=Y)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 112, 112, 64) 9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 112, 112, 64) 256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 112, 112, 64) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 56, 56, 64)   4160        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 56, 56, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 56, 56, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 56, 56, 64)   36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 56, 56, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 56, 56, 256)  16640       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 56, 56, 256)  16640       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 56, 56, 256)  1024        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 56, 56, 256)  1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 56, 56, 256)  0           batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 256)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 56, 56, 64)   16448       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 56, 56, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 56, 56, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 56, 56, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 56, 56, 256)  16640       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 56, 56, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           batch_normalization_7[0][0]      \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 56, 56, 64)   16448       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 56, 56, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 56, 56, 64)   36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 56, 56, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 56, 56, 256)  16640       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 56, 56, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           batch_normalization_10[0][0]     \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 28, 28, 128)  32896       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 28, 28, 128)  512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 28, 28, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 28, 28, 128)  147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 28, 28, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 28, 28, 512)  66048       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 28, 28, 512)  131584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 28, 28, 512)  2048        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 28, 28, 512)  2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 28, 28, 512)  0           batch_normalization_13[0][0]     \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 512)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 28, 28, 128)  65664       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 28, 28, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 28, 28, 128)  147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 28, 28, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 28, 28, 512)  66048       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 28, 28, 512)  2048        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           batch_normalization_17[0][0]     \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 28, 28, 128)  65664       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 28, 28, 128)  512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 128)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 28, 28, 128)  147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 28, 28, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 28, 28, 512)  66048       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 28, 28, 512)  2048        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           batch_normalization_20[0][0]     \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 28, 28, 128)  65664       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 28, 28, 128)  512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 128)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 28, 28, 128)  147584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 28, 28, 128)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 28, 28, 512)  66048       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 28, 28, 512)  2048        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           batch_normalization_23[0][0]     \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 14, 14, 256)  131328      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 14, 14, 256)  1024        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 14, 14, 256)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 14, 14, 256)  590080      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 14, 14, 256)  1024        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 14, 14, 1024) 263168      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 14, 14, 1024) 525312      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 14, 14, 1024) 4096        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 14, 14, 1024) 4096        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_26[0][0]     \n",
      "                                                                 batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 1024) 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 14, 14, 256)  262400      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 14, 14, 256)  1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 256)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 14, 14, 256)  590080      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 14, 14, 256)  1024        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 14, 14, 1024) 263168      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 14, 14, 1024) 4096        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_30[0][0]     \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 14, 14, 256)  262400      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 14, 14, 256)  1024        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 256)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 14, 14, 256)  590080      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 14, 14, 256)  1024        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 14, 14, 1024) 263168      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 14, 14, 1024) 4096        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_33[0][0]     \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 14, 14, 256)  262400      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 14, 14, 256)  1024        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 256)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 14, 14, 256)  590080      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 14, 14, 256)  1024        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 14, 14, 1024) 263168      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 14, 14, 1024) 4096        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_36[0][0]     \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 14, 14, 256)  262400      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 14, 14, 256)  1024        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 256)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 14, 14, 256)  590080      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 14, 14, 256)  1024        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 14, 14, 1024) 263168      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 14, 14, 1024) 4096        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_39[0][0]     \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 14, 14, 256)  262400      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 14, 14, 256)  1024        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 256)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 14, 14, 256)  590080      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 14, 14, 256)  1024        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 14, 14, 1024) 263168      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 14, 14, 1024) 4096        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_42[0][0]     \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 7, 512)    524800      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 7, 512)    2048        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 512)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 512)    2359808     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 512)    2048        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 2048)   2099200     activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 2048)   8192        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 2048)   8192        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_45[0][0]     \n",
      "                                                                 batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 2048)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 512)    1049088     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 512)    2048        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 512)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 512)    2359808     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 512)    2048        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 2048)   8192        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_49[0][0]     \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 512)    1049088     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 512)    2048        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 512)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 512)    2359808     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 512)    2048        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 2048)   8192        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_52[0][0]     \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 1, 2048)   0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1, 1, 1000)   2049000     average_pooling2d[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "identity_block = __import__('2-identity_block').identity_block\n",
    "projection_block = __import__('3-projection_block').projection_block\n",
    "\n",
    "\n",
    "\n",
    "def resnet50():\n",
    "    \"\"\" doc \"\"\"\n",
    "    MaxPooling2D = K.layers.MaxPooling2D\n",
    "    AveragePooling2D = K.layers.AveragePooling2D\n",
    "    Conv2D = K.layers.Conv2D\n",
    "    Dense = K.layers.Dense\n",
    "    BatchNorm = K.layers.BatchNormalization\n",
    "    Activation = K.layers.Activation\n",
    "\n",
    "    def layersConv(X, k, f, s=None, p='same'):\n",
    "        layer = Conv2D(k, f, s, padding=p,\n",
    "                       kernel_initializer='he_normal')(X)\n",
    "        layer = BatchNorm()(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "        return layer\n",
    "\n",
    "    X = K.Input(shape=(224, 224, 3))\n",
    "\n",
    "    layer = layersConv(X, 64, 7, 2)\n",
    "\n",
    "    layerMax = MaxPooling2D(3, 2)(layer)\n",
    "\n",
    "    layer = projection_block(layer, [64, 64, 256])\n",
    "    layer = identity_block(layer, [64, 64, 256])\n",
    "    layer = identity_block(layer, [64, 64, 256])\n",
    "\n",
    "    layer = projection_block(layer, [128, 128, 512])\n",
    "    layer = identity_block(layer, [128, 128, 512])\n",
    "    layer = identity_block(layer, [128, 128, 512])\n",
    "    layer = identity_block(layer, [128, 128, 512])\n",
    "\n",
    "    layer = projection_block(layer, [256, 256, 1024])\n",
    "    layer = identity_block(layer, [256, 256, 1024])\n",
    "    layer = identity_block(layer, [256, 256, 1024])\n",
    "    layer = identity_block(layer, [256, 256, 1024])\n",
    "    layer = identity_block(layer, [256, 256, 1024])\n",
    "    layer = identity_block(layer, [256, 256, 1024])\n",
    "\n",
    "    layer = projection_block(layer, [512, 512, 2048])\n",
    "    layer = identity_block(layer, [512, 512, 2048])\n",
    "    layer = identity_block(layer, [512, 512, 2048])\n",
    "\n",
    "    layerAVG = AveragePooling2D(7, 1)(layer)\n",
    "\n",
    "    Y = Dense(1000, activation=\"softmax\")(layerAVG)\n",
    "\n",
    "    model = K.Model(inputs=X, outputs=Y)\n",
    "    return model\n",
    "if __name__ == '__main__':\n",
    "    model = resnet50()\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_44 (InputLayer)           (None, 56, 56, 64)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_462 (BatchN (None, 56, 56, 64)   256         input_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_457 (Activation)     (None, 56, 56, 64)   0           batch_normalization_462[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_465 (Conv2D)             (None, 56, 56, 32)   2080        activation_457[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_463 (BatchN (None, 56, 56, 32)   128         conv2d_465[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_458 (Activation)     (None, 56, 56, 32)   0           batch_normalization_463[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_466 (Conv2D)             (None, 56, 56, 32)   9248        activation_458[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_189 (Concatenate)   (None, 56, 56, 96)   0           input_44[0][0]                   \n",
      "                                                                 conv2d_466[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_464 (BatchN (None, 56, 56, 96)   384         concatenate_189[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_459 (Activation)     (None, 56, 56, 96)   0           batch_normalization_464[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_467 (Conv2D)             (None, 56, 56, 32)   3104        activation_459[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_465 (BatchN (None, 56, 56, 32)   128         conv2d_467[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_460 (Activation)     (None, 56, 56, 32)   0           batch_normalization_465[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_468 (Conv2D)             (None, 56, 56, 32)   9248        activation_460[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_190 (Concatenate)   (None, 56, 56, 128)  0           concatenate_189[0][0]            \n",
      "                                                                 conv2d_468[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_466 (BatchN (None, 56, 56, 128)  512         concatenate_190[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_461 (Activation)     (None, 56, 56, 128)  0           batch_normalization_466[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_469 (Conv2D)             (None, 56, 56, 32)   4128        activation_461[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_467 (BatchN (None, 56, 56, 32)   128         conv2d_469[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_462 (Activation)     (None, 56, 56, 32)   0           batch_normalization_467[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_470 (Conv2D)             (None, 56, 56, 32)   9248        activation_462[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_191 (Concatenate)   (None, 56, 56, 160)  0           concatenate_190[0][0]            \n",
      "                                                                 conv2d_470[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_468 (BatchN (None, 56, 56, 160)  640         concatenate_191[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_463 (Activation)     (None, 56, 56, 160)  0           batch_normalization_468[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_471 (Conv2D)             (None, 56, 56, 32)   5152        activation_463[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_469 (BatchN (None, 56, 56, 32)   128         conv2d_471[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_464 (Activation)     (None, 56, 56, 32)   0           batch_normalization_469[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_472 (Conv2D)             (None, 56, 56, 32)   9248        activation_464[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_192 (Concatenate)   (None, 56, 56, 192)  0           concatenate_191[0][0]            \n",
      "                                                                 conv2d_472[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_470 (BatchN (None, 56, 56, 192)  768         concatenate_192[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_465 (Activation)     (None, 56, 56, 192)  0           batch_normalization_470[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_473 (Conv2D)             (None, 56, 56, 32)   6176        activation_465[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_471 (BatchN (None, 56, 56, 32)   128         conv2d_473[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_466 (Activation)     (None, 56, 56, 32)   0           batch_normalization_471[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_474 (Conv2D)             (None, 56, 56, 32)   9248        activation_466[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_193 (Concatenate)   (None, 56, 56, 224)  0           concatenate_192[0][0]            \n",
      "                                                                 conv2d_474[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_472 (BatchN (None, 56, 56, 224)  896         concatenate_193[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_467 (Activation)     (None, 56, 56, 224)  0           batch_normalization_472[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_475 (Conv2D)             (None, 56, 56, 32)   7200        activation_467[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_473 (BatchN (None, 56, 56, 32)   128         conv2d_475[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_468 (Activation)     (None, 56, 56, 32)   0           batch_normalization_473[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_476 (Conv2D)             (None, 56, 56, 32)   9248        activation_468[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_194 (Concatenate)   (None, 56, 56, 256)  0           concatenate_193[0][0]            \n",
      "                                                                 conv2d_476[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 87,552\n",
      "Trainable params: 85,440\n",
      "Non-trainable params: 2,112\n",
      "__________________________________________________________________________________________________\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "def dense_block(X, nb_filters, growth_rate, layers):\n",
    "    \"\"\" doc \"\"\"\n",
    "    MaxPooling2D = K.layers.MaxPooling2D\n",
    "    AveragePooling2D = K.layers.AveragePooling2D\n",
    "    Conv2D = K.layers.Conv2D\n",
    "    Dense = K.layers.Dense\n",
    "    BatchNorm = K.layers.BatchNormalization\n",
    "    Activation = K.layers.Activation\n",
    "    Concatenate = K.layers.Concatenate\n",
    "    def layersConv(X, k, f, p='valid', s=1):\n",
    "        layer = Conv2D(k, f, s, padding=p,\n",
    "                       kernel_initializer='he_normal')(X)\n",
    "        return layer\n",
    "\n",
    "    layer_prev = X\n",
    "    for layer in range(layers):\n",
    "        layer_new = BatchNorm()(layer_prev)\n",
    "        layer_new = Activation('relu')(layer_new)\n",
    "        # 4k X\n",
    "        layer_new = layersConv(layer_new, growth_rate, 1, 'same')\n",
    "\n",
    "        layer_new = BatchNorm()(layer_new)\n",
    "        layer_new = Activation('relu')(layer_new)\n",
    "        layer_new = layersConv(layer_new, growth_rate, 3, 'same')\n",
    "        \n",
    "        layer_prev = Concatenate()([layer_prev, layer_new])\n",
    "        \n",
    "\n",
    "        nb_filters += growth_rate\n",
    "\n",
    "    return layer_prev, nb_filters\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X = K.Input(shape=(56, 56, 64))\n",
    "    Y, nb_filters = dense_block(X, 64, 32, 6)\n",
    "    model = K.models.Model(inputs=X, outputs=Y)\n",
    "    model.summary()\n",
    "    print(nb_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 56, 56, 128)       32896     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 28, 28, 128)       0         \n",
      "=================================================================\n",
      "Total params: 33,920\n",
      "Trainable params: 33,408\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "def transition_layer(X, nb_filters, compression):\n",
    "    \"\"\" doc \"\"\"\n",
    "    MaxPooling2D = K.layers.MaxPooling2D\n",
    "    AveragePooling2D = K.layers.AveragePooling2D\n",
    "    Conv2D = K.layers.Conv2D\n",
    "    Dense = K.layers.Dense\n",
    "    BatchNorm = K.layers.BatchNormalization\n",
    "    Activation = K.layers.Activation\n",
    "    Concatenate = K.layers.Concatenate\n",
    "\n",
    "    def layersConv(X, k, f, p='valid', s=1):\n",
    "        layer = Conv2D(k, f, s, padding=p,\n",
    "                       kernel_initializer='he_normal')(X)\n",
    "        return layer\n",
    "\n",
    "    layer_new = BatchNorm()(X)\n",
    "    layer_new = Activation('relu')(layer_new)\n",
    "    nb_filters = int(nb_filters * compression)\n",
    "    layer_new = layersConv(layer_new, nb_filters, 1)\n",
    "    layer_new = AveragePooling2D(2)(layer_new)\n",
    "\n",
    "    return layer_new, nb_filters\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X = K.Input(shape=(56, 56, 256))\n",
    "    Y, nb_filters = transition_layer(X, 256, 0.5)\n",
    "    model = K.models.Model(inputs=X, outputs=Y)\n",
    "    model.summary()\n",
    "    print(nb_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_539 (Conv2D)             (None, 112, 112, 64) 9472        input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_539 (BatchN (None, 112, 112, 64) 256         conv2d_539[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_539 (Activation)     (None, 112, 112, 64) 0           batch_normalization_539[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_540 (BatchN (None, 112, 112, 64) 256         activation_539[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_540 (Activation)     (None, 112, 112, 64) 0           batch_normalization_540[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_540 (Conv2D)             (None, 112, 112, 128 8320        activation_540[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_541 (BatchN (None, 112, 112, 128 512         conv2d_540[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_541 (Activation)     (None, 112, 112, 128 0           batch_normalization_541[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_541 (Conv2D)             (None, 112, 112, 32) 36896       activation_541[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_246 (Concatenate)   (None, 112, 112, 96) 0           activation_539[0][0]             \n",
      "                                                                 conv2d_541[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_542 (BatchN (None, 112, 112, 96) 384         concatenate_246[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_542 (Activation)     (None, 112, 112, 96) 0           batch_normalization_542[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_542 (Conv2D)             (None, 112, 112, 128 12416       activation_542[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_543 (BatchN (None, 112, 112, 128 512         conv2d_542[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_543 (Activation)     (None, 112, 112, 128 0           batch_normalization_543[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_543 (Conv2D)             (None, 112, 112, 32) 36896       activation_543[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_247 (Concatenate)   (None, 112, 112, 128 0           concatenate_246[0][0]            \n",
      "                                                                 conv2d_543[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_544 (BatchN (None, 112, 112, 128 512         concatenate_247[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_544 (Activation)     (None, 112, 112, 128 0           batch_normalization_544[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_544 (Conv2D)             (None, 112, 112, 128 16512       activation_544[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_545 (BatchN (None, 112, 112, 128 512         conv2d_544[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_545 (Activation)     (None, 112, 112, 128 0           batch_normalization_545[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_545 (Conv2D)             (None, 112, 112, 32) 36896       activation_545[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_248 (Concatenate)   (None, 112, 112, 160 0           concatenate_247[0][0]            \n",
      "                                                                 conv2d_545[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_546 (BatchN (None, 112, 112, 160 640         concatenate_248[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_546 (Activation)     (None, 112, 112, 160 0           batch_normalization_546[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_546 (Conv2D)             (None, 112, 112, 128 20608       activation_546[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_547 (BatchN (None, 112, 112, 128 512         conv2d_546[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_547 (Activation)     (None, 112, 112, 128 0           batch_normalization_547[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_547 (Conv2D)             (None, 112, 112, 32) 36896       activation_547[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_249 (Concatenate)   (None, 112, 112, 192 0           concatenate_248[0][0]            \n",
      "                                                                 conv2d_547[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_548 (BatchN (None, 112, 112, 192 768         concatenate_249[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_548 (Activation)     (None, 112, 112, 192 0           batch_normalization_548[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_548 (Conv2D)             (None, 112, 112, 128 24704       activation_548[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_549 (BatchN (None, 112, 112, 128 512         conv2d_548[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_549 (Activation)     (None, 112, 112, 128 0           batch_normalization_549[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_549 (Conv2D)             (None, 112, 112, 32) 36896       activation_549[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_250 (Concatenate)   (None, 112, 112, 224 0           concatenate_249[0][0]            \n",
      "                                                                 conv2d_549[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_550 (BatchN (None, 112, 112, 224 896         concatenate_250[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_550 (Activation)     (None, 112, 112, 224 0           batch_normalization_550[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_550 (Conv2D)             (None, 112, 112, 128 28800       activation_550[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_551 (BatchN (None, 112, 112, 128 512         conv2d_550[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_551 (Activation)     (None, 112, 112, 128 0           batch_normalization_551[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_551 (Conv2D)             (None, 112, 112, 32) 36896       activation_551[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_251 (Concatenate)   (None, 112, 112, 256 0           concatenate_250[0][0]            \n",
      "                                                                 conv2d_551[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_552 (BatchN (None, 112, 112, 256 1024        concatenate_251[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_552 (Activation)     (None, 112, 112, 256 0           batch_normalization_552[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_552 (Conv2D)             (None, 112, 112, 32) 8224        activation_552[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_44 (AveragePo (None, 56, 56, 32)   0           conv2d_552[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_553 (BatchN (None, 56, 56, 32)   128         average_pooling2d_44[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_553 (Activation)     (None, 56, 56, 32)   0           batch_normalization_553[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_553 (Conv2D)             (None, 56, 56, 128)  4224        activation_553[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_554 (BatchN (None, 56, 56, 128)  512         conv2d_553[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_554 (Activation)     (None, 56, 56, 128)  0           batch_normalization_554[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_554 (Conv2D)             (None, 56, 56, 32)   36896       activation_554[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_252 (Concatenate)   (None, 56, 56, 64)   0           average_pooling2d_44[0][0]       \n",
      "                                                                 conv2d_554[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_555 (BatchN (None, 56, 56, 64)   256         concatenate_252[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_555 (Activation)     (None, 56, 56, 64)   0           batch_normalization_555[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_555 (Conv2D)             (None, 56, 56, 128)  8320        activation_555[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_556 (BatchN (None, 56, 56, 128)  512         conv2d_555[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_556 (Activation)     (None, 56, 56, 128)  0           batch_normalization_556[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_556 (Conv2D)             (None, 56, 56, 32)   36896       activation_556[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_253 (Concatenate)   (None, 56, 56, 96)   0           concatenate_252[0][0]            \n",
      "                                                                 conv2d_556[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_557 (BatchN (None, 56, 56, 96)   384         concatenate_253[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_557 (Activation)     (None, 56, 56, 96)   0           batch_normalization_557[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_557 (Conv2D)             (None, 56, 56, 128)  12416       activation_557[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_558 (BatchN (None, 56, 56, 128)  512         conv2d_557[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_558 (Activation)     (None, 56, 56, 128)  0           batch_normalization_558[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_558 (Conv2D)             (None, 56, 56, 32)   36896       activation_558[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_254 (Concatenate)   (None, 56, 56, 128)  0           concatenate_253[0][0]            \n",
      "                                                                 conv2d_558[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_559 (BatchN (None, 56, 56, 128)  512         concatenate_254[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_559 (Activation)     (None, 56, 56, 128)  0           batch_normalization_559[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_559 (Conv2D)             (None, 56, 56, 128)  16512       activation_559[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_560 (BatchN (None, 56, 56, 128)  512         conv2d_559[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_560 (Activation)     (None, 56, 56, 128)  0           batch_normalization_560[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_560 (Conv2D)             (None, 56, 56, 32)   36896       activation_560[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_255 (Concatenate)   (None, 56, 56, 160)  0           concatenate_254[0][0]            \n",
      "                                                                 conv2d_560[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_561 (BatchN (None, 56, 56, 160)  640         concatenate_255[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_561 (Activation)     (None, 56, 56, 160)  0           batch_normalization_561[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_561 (Conv2D)             (None, 56, 56, 128)  20608       activation_561[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_562 (BatchN (None, 56, 56, 128)  512         conv2d_561[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_562 (Activation)     (None, 56, 56, 128)  0           batch_normalization_562[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_562 (Conv2D)             (None, 56, 56, 32)   36896       activation_562[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_256 (Concatenate)   (None, 56, 56, 192)  0           concatenate_255[0][0]            \n",
      "                                                                 conv2d_562[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_563 (BatchN (None, 56, 56, 192)  768         concatenate_256[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_563 (Activation)     (None, 56, 56, 192)  0           batch_normalization_563[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_563 (Conv2D)             (None, 56, 56, 128)  24704       activation_563[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_564 (BatchN (None, 56, 56, 128)  512         conv2d_563[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_564 (Activation)     (None, 56, 56, 128)  0           batch_normalization_564[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_564 (Conv2D)             (None, 56, 56, 32)   36896       activation_564[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_257 (Concatenate)   (None, 56, 56, 224)  0           concatenate_256[0][0]            \n",
      "                                                                 conv2d_564[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_565 (BatchN (None, 56, 56, 224)  896         concatenate_257[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_565 (Activation)     (None, 56, 56, 224)  0           batch_normalization_565[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_565 (Conv2D)             (None, 56, 56, 112)  25200       activation_565[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_45 (AveragePo (None, 28, 28, 112)  0           conv2d_565[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_566 (BatchN (None, 28, 28, 112)  448         average_pooling2d_45[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_566 (Activation)     (None, 28, 28, 112)  0           batch_normalization_566[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_566 (Conv2D)             (None, 28, 28, 128)  14464       activation_566[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_567 (BatchN (None, 28, 28, 128)  512         conv2d_566[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_567 (Activation)     (None, 28, 28, 128)  0           batch_normalization_567[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_567 (Conv2D)             (None, 28, 28, 32)   36896       activation_567[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_258 (Concatenate)   (None, 28, 28, 144)  0           average_pooling2d_45[0][0]       \n",
      "                                                                 conv2d_567[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_568 (BatchN (None, 28, 28, 144)  576         concatenate_258[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_568 (Activation)     (None, 28, 28, 144)  0           batch_normalization_568[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_568 (Conv2D)             (None, 28, 28, 128)  18560       activation_568[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_569 (BatchN (None, 28, 28, 128)  512         conv2d_568[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_569 (Activation)     (None, 28, 28, 128)  0           batch_normalization_569[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_569 (Conv2D)             (None, 28, 28, 32)   36896       activation_569[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_259 (Concatenate)   (None, 28, 28, 176)  0           concatenate_258[0][0]            \n",
      "                                                                 conv2d_569[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_570 (BatchN (None, 28, 28, 176)  704         concatenate_259[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_570 (Activation)     (None, 28, 28, 176)  0           batch_normalization_570[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_570 (Conv2D)             (None, 28, 28, 128)  22656       activation_570[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_571 (BatchN (None, 28, 28, 128)  512         conv2d_570[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_571 (Activation)     (None, 28, 28, 128)  0           batch_normalization_571[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_571 (Conv2D)             (None, 28, 28, 32)   36896       activation_571[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_260 (Concatenate)   (None, 28, 28, 208)  0           concatenate_259[0][0]            \n",
      "                                                                 conv2d_571[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_572 (BatchN (None, 28, 28, 208)  832         concatenate_260[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_572 (Activation)     (None, 28, 28, 208)  0           batch_normalization_572[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_572 (Conv2D)             (None, 28, 28, 128)  26752       activation_572[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_573 (BatchN (None, 28, 28, 128)  512         conv2d_572[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_573 (Activation)     (None, 28, 28, 128)  0           batch_normalization_573[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_573 (Conv2D)             (None, 28, 28, 32)   36896       activation_573[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_261 (Concatenate)   (None, 28, 28, 240)  0           concatenate_260[0][0]            \n",
      "                                                                 conv2d_573[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_574 (BatchN (None, 28, 28, 240)  960         concatenate_261[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_574 (Activation)     (None, 28, 28, 240)  0           batch_normalization_574[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_574 (Conv2D)             (None, 28, 28, 128)  30848       activation_574[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_575 (BatchN (None, 28, 28, 128)  512         conv2d_574[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_575 (Activation)     (None, 28, 28, 128)  0           batch_normalization_575[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_575 (Conv2D)             (None, 28, 28, 32)   36896       activation_575[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_262 (Concatenate)   (None, 28, 28, 272)  0           concatenate_261[0][0]            \n",
      "                                                                 conv2d_575[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_576 (BatchN (None, 28, 28, 272)  1088        concatenate_262[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_576 (Activation)     (None, 28, 28, 272)  0           batch_normalization_576[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_576 (Conv2D)             (None, 28, 28, 128)  34944       activation_576[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_577 (BatchN (None, 28, 28, 128)  512         conv2d_576[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_577 (Activation)     (None, 28, 28, 128)  0           batch_normalization_577[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_577 (Conv2D)             (None, 28, 28, 32)   36896       activation_577[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_263 (Concatenate)   (None, 28, 28, 304)  0           concatenate_262[0][0]            \n",
      "                                                                 conv2d_577[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_578 (BatchN (None, 28, 28, 304)  1216        concatenate_263[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_578 (Activation)     (None, 28, 28, 304)  0           batch_normalization_578[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_578 (Conv2D)             (None, 28, 28, 152)  46360       activation_578[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_46 (AveragePo (None, 14, 14, 152)  0           conv2d_578[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_579 (BatchN (None, 14, 14, 152)  608         average_pooling2d_46[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_579 (Activation)     (None, 14, 14, 152)  0           batch_normalization_579[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_579 (Conv2D)             (None, 14, 14, 128)  19584       activation_579[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_580 (BatchN (None, 14, 14, 128)  512         conv2d_579[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_580 (Activation)     (None, 14, 14, 128)  0           batch_normalization_580[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_580 (Conv2D)             (None, 14, 14, 32)   36896       activation_580[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_264 (Concatenate)   (None, 14, 14, 184)  0           average_pooling2d_46[0][0]       \n",
      "                                                                 conv2d_580[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_581 (BatchN (None, 14, 14, 184)  736         concatenate_264[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_581 (Activation)     (None, 14, 14, 184)  0           batch_normalization_581[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_581 (Conv2D)             (None, 14, 14, 128)  23680       activation_581[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_582 (BatchN (None, 14, 14, 128)  512         conv2d_581[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_582 (Activation)     (None, 14, 14, 128)  0           batch_normalization_582[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_582 (Conv2D)             (None, 14, 14, 32)   36896       activation_582[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_265 (Concatenate)   (None, 14, 14, 216)  0           concatenate_264[0][0]            \n",
      "                                                                 conv2d_582[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_583 (BatchN (None, 14, 14, 216)  864         concatenate_265[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_583 (Activation)     (None, 14, 14, 216)  0           batch_normalization_583[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_583 (Conv2D)             (None, 14, 14, 128)  27776       activation_583[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_584 (BatchN (None, 14, 14, 128)  512         conv2d_583[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_584 (Activation)     (None, 14, 14, 128)  0           batch_normalization_584[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_584 (Conv2D)             (None, 14, 14, 32)   36896       activation_584[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_266 (Concatenate)   (None, 14, 14, 248)  0           concatenate_265[0][0]            \n",
      "                                                                 conv2d_584[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_585 (BatchN (None, 14, 14, 248)  992         concatenate_266[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_585 (Activation)     (None, 14, 14, 248)  0           batch_normalization_585[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_585 (Conv2D)             (None, 14, 14, 128)  31872       activation_585[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_586 (BatchN (None, 14, 14, 128)  512         conv2d_585[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_586 (Activation)     (None, 14, 14, 128)  0           batch_normalization_586[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_586 (Conv2D)             (None, 14, 14, 32)   36896       activation_586[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_267 (Concatenate)   (None, 14, 14, 280)  0           concatenate_266[0][0]            \n",
      "                                                                 conv2d_586[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_587 (BatchN (None, 14, 14, 280)  1120        concatenate_267[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_587 (Activation)     (None, 14, 14, 280)  0           batch_normalization_587[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_587 (Conv2D)             (None, 14, 14, 128)  35968       activation_587[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_588 (BatchN (None, 14, 14, 128)  512         conv2d_587[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_588 (Activation)     (None, 14, 14, 128)  0           batch_normalization_588[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_588 (Conv2D)             (None, 14, 14, 32)   36896       activation_588[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_268 (Concatenate)   (None, 14, 14, 312)  0           concatenate_267[0][0]            \n",
      "                                                                 conv2d_588[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_589 (BatchN (None, 14, 14, 312)  1248        concatenate_268[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_589 (Activation)     (None, 14, 14, 312)  0           batch_normalization_589[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_589 (Conv2D)             (None, 14, 14, 128)  40064       activation_589[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_590 (BatchN (None, 14, 14, 128)  512         conv2d_589[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_590 (Activation)     (None, 14, 14, 128)  0           batch_normalization_590[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_590 (Conv2D)             (None, 14, 14, 32)   36896       activation_590[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_269 (Concatenate)   (None, 14, 14, 344)  0           concatenate_268[0][0]            \n",
      "                                                                 conv2d_590[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_47 (AveragePo (None, 2, 2, 344)    0           concatenate_269[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 2, 2, 1000)   345000      average_pooling2d_47[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 1,877,072\n",
      "Trainable params: 1,861,072\n",
      "Non-trainable params: 16,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dense_block = __import__('5-dense_block').dense_block\n",
    "transition_layer = __import__('6-transition_layer').transition_layer\n",
    "\n",
    "\n",
    "def densenet121(growth_rate=32, compression=1.0):\n",
    "    \"\"\" doc \"\"\"\n",
    "    MaxPooling2D = K.layers.MaxPooling2D\n",
    "    AveragePooling2D = K.layers.AveragePooling2D\n",
    "    Conv2D = K.layers.Conv2D\n",
    "    Dense = K.layers.Dense\n",
    "    BatchNorm = K.layers.BatchNormalization\n",
    "    Activation = K.layers.Activation\n",
    "\n",
    "    def layersConv(X, k, f, s=None, p='same'):\n",
    "        layer = Conv2D(k, f, s, padding=p,\n",
    "                       kernel_initializer='he_normal')(X)\n",
    "        layer = BatchNorm()(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "        return layer\n",
    "\n",
    "    X = K.Input(shape=(224, 224, 3))\n",
    "    nb_filters = 64\n",
    "    layers = 6\n",
    "    # Convolution\n",
    "    layer = layersConv(X, nb_filters, 7, 2)\n",
    "\n",
    "    # Pooling\n",
    "    layerMax = MaxPooling2D(3, 2, padding=\"same\")(layer)\n",
    "\n",
    "    # Dense Block / Transition Layer (1)\n",
    "    layer, nb_filters = dense_block(layer, nb_filters, growth_rate, layers)\n",
    "    layer, nb_filters = transition_layer(layer, nb_filters, compression)\n",
    "\n",
    "    # Dense Block / Transition Layer (2)\n",
    "    layer, nb_filters = dense_block(layer, nb_filters, growth_rate, layers)\n",
    "    layer, nb_filters = transition_layer(layer, nb_filters, compression)\n",
    "\n",
    "    # Dense Block / Transition Layer (3)\n",
    "    layer, nb_filters = dense_block(layer, nb_filters, growth_rate, layers)\n",
    "    layer, nb_filters = transition_layer(layer, nb_filters, compression)\n",
    "\n",
    "    # Dense Block (3)\n",
    "    layer, nb_filters = dense_block(layer, nb_filters, growth_rate, layers)\n",
    "\n",
    "    # Classification Layer (Pooling + 1000D fully-connected, softmax)\n",
    "    layerAVG = AveragePooling2D(7, 7, padding=\"same\")(layer)\n",
    "    Y = Dense(1000, activation=\"softmax\")(layerAVG)\n",
    "\n",
    "    model = K.Model(inputs=X, outputs=Y)\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = densenet121(32, 0.5)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
