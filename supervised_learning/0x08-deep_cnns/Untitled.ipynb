{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cp 4-resnet50.py 5-dense_block.py\n",
    "#!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 224, 224, 96) 384         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 224, 224, 16) 64          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 224, 224, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 224, 224, 64) 256         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 224, 224, 128 110720      conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 224, 224, 32) 12832       conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 224, 224, 32) 128         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 224, 224, 256 0           conv2d[0][0]                     \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 124,384\n",
      "Trainable params: 124,384\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import tensorflow.keras as K\n",
    "#inception_block = __import__('0-inception_block').inception_block\n",
    "def inception_block(A_prev, filters):\n",
    "    \"\"\" doc \"\"\"\n",
    "    MaxPooling2D = K.layers.MaxPooling2D\n",
    "    Conv2D = K.layers.Conv2D\n",
    "    Concatenate = K.layers.Concatenate()\n",
    "    \n",
    "    F1, F3R, F3, F5R, F5, FPP = filters\n",
    "    \n",
    "    layer1x1_0 = Conv2D(F1, 1, activation='relu')(A_prev) #\n",
    "    \n",
    "    layer1x1_1 = Conv2D(F3R, 1, padding='same', activation='relu')(A_prev)\n",
    "    \n",
    "    layer3x3 = Conv2D(F3, 3, padding='same', activation='relu')(layer1x1_1) #\n",
    "    \n",
    "    layer1x1_2 = Conv2D(F5R, 1, padding='same', activation='relu')(A_prev)\n",
    "    \n",
    "    layer5x5 = Conv2D(F5, 5, padding='same',  activation='relu')(layer1x1_2) #\n",
    "    \n",
    "    layerMax = MaxPooling2D(1)(A_prev)\n",
    "    \n",
    "    layer1x1_3 = Conv2D(FPP, 1, padding='same', activation='relu')(layerMax) #\n",
    "    \n",
    "    layer_out = Concatenate([layer1x1_0, layer3x3, layer5x5, layer1x1_3])\n",
    "    return layer_out\n",
    "if __name__ == '__main__':\n",
    "    X = K.Input(shape=(224, 224, 3))\n",
    "    Y = inception_block(X, [64, 96, 128, 16, 32, 32])\n",
    "    model = K.models.Model(inputs=X, outputs=Y)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " [(None, 224, 224, 64), (None, 222, 222, 128), (None, 220, 220, 32), (None, 224, 224, 32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# one by one from the table\n",
    "def inception_network():\n",
    "    \"\"\" doc \"\"\"\n",
    "    MaxPooling2D = K.layers.MaxPooling2D\n",
    "    AveragePooling2D = K.layers.AveragePooling2D\n",
    "    Conv2D = K.layers.Conv2D\n",
    "    Dropout = K.layers.Dropout(rate=0.6)\n",
    "    Dense = K.layers.Dense\n",
    "    X = K.Input(shape=(224, 224, 3))\n",
    "    \n",
    "    layer7x7 = Conv2D(64, 7, 2, padding='same',  activation='relu')(X)\n",
    "    layerMax = MaxPooling2D(3, 2, padding='same')(layer7x7)\n",
    "    \n",
    "    layer3x3 = Conv2D(64, 1, 1,  activation='relu')(layerMax)\n",
    "    layer3x3 = Conv2D(192, 3, 1, padding='same',  activation='relu')(layer3x3)\n",
    "    layerMax_2 = MaxPooling2D(3, 2, padding='same')(layer3x3)\n",
    "\n",
    "    inception = inception_block(layerMax_2, [64, 96, 128, 16, 32, 32])\n",
    "    inception = inception_block(inception, [128, 128, 192, 32, 96, 64])\n",
    "    \n",
    "    layerMax_2 = MaxPooling2D(3, 2, padding='same')(inception)\n",
    "    inception = inception_block(layerMax_2, [192, 96, 208, 16, 48, 64])\n",
    "    inception = inception_block(inception, [160, 112, 224, 24, 64, 64])\n",
    "    inception = inception_block(inception, [128, 128, 256, 24, 64, 64])\n",
    "    inception = inception_block(inception, [112, 144, 288, 32, 64, 64])\n",
    "    inception = inception_block(inception, [256, 160, 320, 32, 128, 128])\n",
    "    layerMax_2 = MaxPooling2D(3, 2, padding='same')(inception)\n",
    "    inception = inception_block(layerMax_2, [256, 160, 320, 32, 128, 128])\n",
    "    inception = inception_block(inception, [384, 192, 384, 48, 128, 128])\n",
    "    layerAVG_2 = AveragePooling2D(7, 1)(inception)\n",
    "    dropped = Dropout(layerAVG_2)\n",
    "    # dropped = Dense(1000, activation=\"relu\")(dropped)\n",
    "    Y = Dense(1000, activation=\"softmax\")(dropped)\n",
    "\n",
    "    model = K.Model(inputs=X, outputs=Y)\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = inception_network()\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 224, 224, 256 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 224, 224, 64) 16448       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 224, 224, 64) 256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 224, 224, 64) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 224, 224, 64) 36928       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 224, 224, 64) 256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 224, 224, 64) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 224, 224, 256 16640       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 224, 224, 256 1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 224, 224, 256 0           batch_normalization_8[0][0]      \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 224, 224, 256 0           add_2[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 71,552\n",
      "Trainable params: 70,784\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def identity_block(A_prev, filters):\n",
    "    \"\"\" doc \"\"\"\n",
    "    Conv2D = K.layers.Conv2D\n",
    "    BatchNorm = K.layers.BatchNormalization\n",
    "    Activation = K.layers.Activation\n",
    "    Add = K.layers.Add\n",
    "    F11, F3, F12 = filters\n",
    "    layer1x1 = Conv2D(F11, 1, padding='same', kernel_initializer='he_normal')(A_prev)\n",
    "    layer1x1 = BatchNorm()(layer1x1)\n",
    "    layer1x1 = Activation('relu')(layer1x1)\n",
    "\n",
    "    layer3x3 = Conv2D(F3, 3, padding='same', kernel_initializer='he_normal')(layer1x1)\n",
    "    layer3x3 = BatchNorm()(layer3x3)\n",
    "    layer3x3 = Activation('relu')(layer3x3)\n",
    "\n",
    "    layer1x1 = Conv2D(F12, 1, padding='same', kernel_initializer='he_normal')(layer3x3)\n",
    "    layer1x1 = BatchNorm()(layer1x1)\n",
    "\n",
    "    layer_out = Add()([layer1x1, A_prev])\n",
    "    layer_out = Activation('relu')(layer_out)\n",
    "\n",
    "    return layer_out\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X = K.Input(shape=(224, 224, 256))\n",
    "    Y = identity_block(X, [64, 64, 256])\n",
    "    model = K.models.Model(inputs=X, outputs=Y)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_29 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1397 (Conv2D)            (None, 112, 112, 64) 256         input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1397 (Batch (None, 112, 112, 64) 256         conv2d_1397[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1291 (Activation)    (None, 112, 112, 64) 0           batch_normalization_1397[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1398 (Conv2D)            (None, 112, 112, 64) 36928       activation_1291[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1398 (Batch (None, 112, 112, 64) 256         conv2d_1398[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1292 (Activation)    (None, 112, 112, 64) 0           batch_normalization_1398[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1399 (Conv2D)            (None, 112, 112, 256 16640       activation_1292[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1400 (Conv2D)            (None, 112, 112, 256 1024        input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1399 (Batch (None, 112, 112, 256 1024        conv2d_1399[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1400 (Batch (None, 112, 112, 256 1024        conv2d_1400[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_418 (Add)                   (None, 112, 112, 256 0           batch_normalization_1399[0][0]   \n",
      "                                                                 batch_normalization_1400[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1293 (Activation)    (None, 112, 112, 256 0           add_418[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 57,408\n",
      "Trainable params: 56,128\n",
      "Non-trainable params: 1,280\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "projection_block = __import__('3-projection_block').projection_block\n",
    "\n",
    "def projection_block(A_prev, filters, s=2):\n",
    "    \"\"\" doc \"\"\"\n",
    "    Conv2D = K.layers.Conv2D\n",
    "    BatchNorm = K.layers.BatchNormalization\n",
    "    Activation = K.layers.Activation\n",
    "    Add = K.layers.Add\n",
    "    F11, F3, F12 = filters\n",
    "\n",
    "    layer1x1 = Conv2D(F11, 1, s, padding='same',\n",
    "                      kernel_initializer='he_normal')(A_prev)\n",
    "    layer1x1 = BatchNorm()(layer1x1)\n",
    "    layer1x1 = Activation('relu')(layer1x1)\n",
    "\n",
    "    layer3x3 = Conv2D(F3, 3, padding='same',\n",
    "                      kernel_initializer='he_normal')(layer1x1)\n",
    "    layer3x3 = BatchNorm()(layer3x3)\n",
    "    layer3x3 = Activation('relu')(layer3x3)\n",
    "\n",
    "    layer1x1 = Conv2D(F12, 1, padding='same',\n",
    "                      kernel_initializer='he_normal')(layer3x3)\n",
    "    layer1x1 = BatchNorm()(layer1x1)  #\n",
    "    \n",
    "    layer1x1_s = Conv2D(F12, 1, s,\n",
    "                      kernel_initializer='he_normal')(A_prev)\n",
    "    layer1x1_s = BatchNorm()(layer1x1_s)  #\n",
    "\n",
    "    layer_out = Add()([layer1x1, layer1x1_s])\n",
    "    layer_out = Activation('relu')(layer_out)\n",
    "\n",
    "    return layer_out\n",
    "if __name__ == '__main__':\n",
    "    X = K.Input(shape=(224, 224, 3))\n",
    "    Y = projection_block(X, [64, 64, 256])\n",
    "    model = K.models.Model(inputs=X, outputs=Y)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_36 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1719 (Conv2D)            (None, 112, 112, 64) 9472        input_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1719 (Batch (None, 112, 112, 64) 256         conv2d_1719[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1588 (Activation)    (None, 112, 112, 64) 0           batch_normalization_1719[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1720 (Conv2D)            (None, 112, 112, 64) 4160        activation_1588[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1720 (Batch (None, 112, 112, 64) 256         conv2d_1720[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1589 (Activation)    (None, 112, 112, 64) 0           batch_normalization_1720[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1721 (Conv2D)            (None, 112, 112, 64) 36928       activation_1589[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1721 (Batch (None, 112, 112, 64) 256         conv2d_1721[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1590 (Activation)    (None, 112, 112, 64) 0           batch_normalization_1721[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1722 (Conv2D)            (None, 112, 112, 256 16640       activation_1590[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1723 (Conv2D)            (None, 112, 112, 256 16640       activation_1588[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1722 (Batch (None, 112, 112, 256 1024        conv2d_1722[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1723 (Batch (None, 112, 112, 256 1024        conv2d_1723[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_515 (Add)                   (None, 112, 112, 256 0           batch_normalization_1722[0][0]   \n",
      "                                                                 batch_normalization_1723[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1591 (Activation)    (None, 112, 112, 256 0           add_515[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1724 (Conv2D)            (None, 112, 112, 64) 16448       activation_1591[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1724 (Batch (None, 112, 112, 64) 256         conv2d_1724[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1592 (Activation)    (None, 112, 112, 64) 0           batch_normalization_1724[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1725 (Conv2D)            (None, 112, 112, 64) 36928       activation_1592[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1725 (Batch (None, 112, 112, 64) 256         conv2d_1725[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1593 (Activation)    (None, 112, 112, 64) 0           batch_normalization_1725[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1726 (Conv2D)            (None, 112, 112, 256 16640       activation_1593[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1726 (Batch (None, 112, 112, 256 1024        conv2d_1726[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_516 (Add)                   (None, 112, 112, 256 0           batch_normalization_1726[0][0]   \n",
      "                                                                 activation_1591[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1594 (Activation)    (None, 112, 112, 256 0           add_516[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1727 (Conv2D)            (None, 112, 112, 64) 16448       activation_1594[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1727 (Batch (None, 112, 112, 64) 256         conv2d_1727[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1595 (Activation)    (None, 112, 112, 64) 0           batch_normalization_1727[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1728 (Conv2D)            (None, 112, 112, 64) 36928       activation_1595[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1728 (Batch (None, 112, 112, 64) 256         conv2d_1728[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1596 (Activation)    (None, 112, 112, 64) 0           batch_normalization_1728[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1729 (Conv2D)            (None, 112, 112, 256 16640       activation_1596[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1729 (Batch (None, 112, 112, 256 1024        conv2d_1729[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_517 (Add)                   (None, 112, 112, 256 0           batch_normalization_1729[0][0]   \n",
      "                                                                 activation_1594[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1597 (Activation)    (None, 112, 112, 256 0           add_517[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1730 (Conv2D)            (None, 56, 56, 128)  32896       activation_1597[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1730 (Batch (None, 56, 56, 128)  512         conv2d_1730[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1598 (Activation)    (None, 56, 56, 128)  0           batch_normalization_1730[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1731 (Conv2D)            (None, 56, 56, 128)  147584      activation_1598[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1731 (Batch (None, 56, 56, 128)  512         conv2d_1731[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1599 (Activation)    (None, 56, 56, 128)  0           batch_normalization_1731[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1732 (Conv2D)            (None, 56, 56, 512)  66048       activation_1599[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1733 (Conv2D)            (None, 56, 56, 512)  131584      activation_1597[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1732 (Batch (None, 56, 56, 512)  2048        conv2d_1732[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1733 (Batch (None, 56, 56, 512)  2048        conv2d_1733[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_518 (Add)                   (None, 56, 56, 512)  0           batch_normalization_1732[0][0]   \n",
      "                                                                 batch_normalization_1733[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1600 (Activation)    (None, 56, 56, 512)  0           add_518[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1734 (Conv2D)            (None, 56, 56, 128)  65664       activation_1600[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1734 (Batch (None, 56, 56, 128)  512         conv2d_1734[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1601 (Activation)    (None, 56, 56, 128)  0           batch_normalization_1734[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1735 (Conv2D)            (None, 56, 56, 128)  147584      activation_1601[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1735 (Batch (None, 56, 56, 128)  512         conv2d_1735[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1602 (Activation)    (None, 56, 56, 128)  0           batch_normalization_1735[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1736 (Conv2D)            (None, 56, 56, 512)  66048       activation_1602[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1736 (Batch (None, 56, 56, 512)  2048        conv2d_1736[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_519 (Add)                   (None, 56, 56, 512)  0           batch_normalization_1736[0][0]   \n",
      "                                                                 activation_1600[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1603 (Activation)    (None, 56, 56, 512)  0           add_519[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1737 (Conv2D)            (None, 56, 56, 128)  65664       activation_1603[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1737 (Batch (None, 56, 56, 128)  512         conv2d_1737[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1604 (Activation)    (None, 56, 56, 128)  0           batch_normalization_1737[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1738 (Conv2D)            (None, 56, 56, 128)  147584      activation_1604[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1738 (Batch (None, 56, 56, 128)  512         conv2d_1738[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1605 (Activation)    (None, 56, 56, 128)  0           batch_normalization_1738[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1739 (Conv2D)            (None, 56, 56, 512)  66048       activation_1605[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1739 (Batch (None, 56, 56, 512)  2048        conv2d_1739[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_520 (Add)                   (None, 56, 56, 512)  0           batch_normalization_1739[0][0]   \n",
      "                                                                 activation_1603[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1606 (Activation)    (None, 56, 56, 512)  0           add_520[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1740 (Conv2D)            (None, 56, 56, 128)  65664       activation_1606[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1740 (Batch (None, 56, 56, 128)  512         conv2d_1740[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1607 (Activation)    (None, 56, 56, 128)  0           batch_normalization_1740[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1741 (Conv2D)            (None, 56, 56, 128)  147584      activation_1607[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1741 (Batch (None, 56, 56, 128)  512         conv2d_1741[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1608 (Activation)    (None, 56, 56, 128)  0           batch_normalization_1741[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1742 (Conv2D)            (None, 56, 56, 512)  66048       activation_1608[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1742 (Batch (None, 56, 56, 512)  2048        conv2d_1742[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_521 (Add)                   (None, 56, 56, 512)  0           batch_normalization_1742[0][0]   \n",
      "                                                                 activation_1606[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1609 (Activation)    (None, 56, 56, 512)  0           add_521[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1743 (Conv2D)            (None, 28, 28, 256)  131328      activation_1609[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1743 (Batch (None, 28, 28, 256)  1024        conv2d_1743[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1610 (Activation)    (None, 28, 28, 256)  0           batch_normalization_1743[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1744 (Conv2D)            (None, 28, 28, 256)  590080      activation_1610[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1744 (Batch (None, 28, 28, 256)  1024        conv2d_1744[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1611 (Activation)    (None, 28, 28, 256)  0           batch_normalization_1744[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1745 (Conv2D)            (None, 28, 28, 1024) 263168      activation_1611[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1746 (Conv2D)            (None, 28, 28, 1024) 525312      activation_1609[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1745 (Batch (None, 28, 28, 1024) 4096        conv2d_1745[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1746 (Batch (None, 28, 28, 1024) 4096        conv2d_1746[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_522 (Add)                   (None, 28, 28, 1024) 0           batch_normalization_1745[0][0]   \n",
      "                                                                 batch_normalization_1746[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1612 (Activation)    (None, 28, 28, 1024) 0           add_522[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1747 (Conv2D)            (None, 28, 28, 256)  262400      activation_1612[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1747 (Batch (None, 28, 28, 256)  1024        conv2d_1747[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1613 (Activation)    (None, 28, 28, 256)  0           batch_normalization_1747[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1748 (Conv2D)            (None, 28, 28, 256)  590080      activation_1613[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1748 (Batch (None, 28, 28, 256)  1024        conv2d_1748[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1614 (Activation)    (None, 28, 28, 256)  0           batch_normalization_1748[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1749 (Conv2D)            (None, 28, 28, 1024) 263168      activation_1614[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1749 (Batch (None, 28, 28, 1024) 4096        conv2d_1749[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_523 (Add)                   (None, 28, 28, 1024) 0           batch_normalization_1749[0][0]   \n",
      "                                                                 activation_1612[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1615 (Activation)    (None, 28, 28, 1024) 0           add_523[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1750 (Conv2D)            (None, 28, 28, 256)  262400      activation_1615[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1750 (Batch (None, 28, 28, 256)  1024        conv2d_1750[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1616 (Activation)    (None, 28, 28, 256)  0           batch_normalization_1750[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1751 (Conv2D)            (None, 28, 28, 256)  590080      activation_1616[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1751 (Batch (None, 28, 28, 256)  1024        conv2d_1751[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1617 (Activation)    (None, 28, 28, 256)  0           batch_normalization_1751[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1752 (Conv2D)            (None, 28, 28, 1024) 263168      activation_1617[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1752 (Batch (None, 28, 28, 1024) 4096        conv2d_1752[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_524 (Add)                   (None, 28, 28, 1024) 0           batch_normalization_1752[0][0]   \n",
      "                                                                 activation_1615[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1618 (Activation)    (None, 28, 28, 1024) 0           add_524[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1753 (Conv2D)            (None, 28, 28, 256)  262400      activation_1618[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1753 (Batch (None, 28, 28, 256)  1024        conv2d_1753[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1619 (Activation)    (None, 28, 28, 256)  0           batch_normalization_1753[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1754 (Conv2D)            (None, 28, 28, 256)  590080      activation_1619[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1754 (Batch (None, 28, 28, 256)  1024        conv2d_1754[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1620 (Activation)    (None, 28, 28, 256)  0           batch_normalization_1754[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1755 (Conv2D)            (None, 28, 28, 1024) 263168      activation_1620[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1755 (Batch (None, 28, 28, 1024) 4096        conv2d_1755[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_525 (Add)                   (None, 28, 28, 1024) 0           batch_normalization_1755[0][0]   \n",
      "                                                                 activation_1618[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1621 (Activation)    (None, 28, 28, 1024) 0           add_525[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1756 (Conv2D)            (None, 28, 28, 256)  262400      activation_1621[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1756 (Batch (None, 28, 28, 256)  1024        conv2d_1756[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1622 (Activation)    (None, 28, 28, 256)  0           batch_normalization_1756[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1757 (Conv2D)            (None, 28, 28, 256)  590080      activation_1622[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1757 (Batch (None, 28, 28, 256)  1024        conv2d_1757[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1623 (Activation)    (None, 28, 28, 256)  0           batch_normalization_1757[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1758 (Conv2D)            (None, 28, 28, 1024) 263168      activation_1623[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1758 (Batch (None, 28, 28, 1024) 4096        conv2d_1758[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_526 (Add)                   (None, 28, 28, 1024) 0           batch_normalization_1758[0][0]   \n",
      "                                                                 activation_1621[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1624 (Activation)    (None, 28, 28, 1024) 0           add_526[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1759 (Conv2D)            (None, 28, 28, 256)  262400      activation_1624[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1759 (Batch (None, 28, 28, 256)  1024        conv2d_1759[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1625 (Activation)    (None, 28, 28, 256)  0           batch_normalization_1759[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1760 (Conv2D)            (None, 28, 28, 256)  590080      activation_1625[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1760 (Batch (None, 28, 28, 256)  1024        conv2d_1760[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1626 (Activation)    (None, 28, 28, 256)  0           batch_normalization_1760[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1761 (Conv2D)            (None, 28, 28, 1024) 263168      activation_1626[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1761 (Batch (None, 28, 28, 1024) 4096        conv2d_1761[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_527 (Add)                   (None, 28, 28, 1024) 0           batch_normalization_1761[0][0]   \n",
      "                                                                 activation_1624[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1627 (Activation)    (None, 28, 28, 1024) 0           add_527[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1762 (Conv2D)            (None, 14, 14, 512)  524800      activation_1627[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1762 (Batch (None, 14, 14, 512)  2048        conv2d_1762[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1628 (Activation)    (None, 14, 14, 512)  0           batch_normalization_1762[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1763 (Conv2D)            (None, 14, 14, 512)  2359808     activation_1628[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1763 (Batch (None, 14, 14, 512)  2048        conv2d_1763[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1629 (Activation)    (None, 14, 14, 512)  0           batch_normalization_1763[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1764 (Conv2D)            (None, 14, 14, 2048) 1050624     activation_1629[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1765 (Conv2D)            (None, 14, 14, 2048) 2099200     activation_1627[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1764 (Batch (None, 14, 14, 2048) 8192        conv2d_1764[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1765 (Batch (None, 14, 14, 2048) 8192        conv2d_1765[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_528 (Add)                   (None, 14, 14, 2048) 0           batch_normalization_1764[0][0]   \n",
      "                                                                 batch_normalization_1765[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1630 (Activation)    (None, 14, 14, 2048) 0           add_528[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1766 (Conv2D)            (None, 14, 14, 512)  1049088     activation_1630[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1766 (Batch (None, 14, 14, 512)  2048        conv2d_1766[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1631 (Activation)    (None, 14, 14, 512)  0           batch_normalization_1766[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1767 (Conv2D)            (None, 14, 14, 512)  2359808     activation_1631[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1767 (Batch (None, 14, 14, 512)  2048        conv2d_1767[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1632 (Activation)    (None, 14, 14, 512)  0           batch_normalization_1767[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1768 (Conv2D)            (None, 14, 14, 2048) 1050624     activation_1632[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1768 (Batch (None, 14, 14, 2048) 8192        conv2d_1768[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_529 (Add)                   (None, 14, 14, 2048) 0           batch_normalization_1768[0][0]   \n",
      "                                                                 activation_1630[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1633 (Activation)    (None, 14, 14, 2048) 0           add_529[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1769 (Conv2D)            (None, 14, 14, 512)  1049088     activation_1633[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1769 (Batch (None, 14, 14, 512)  2048        conv2d_1769[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1634 (Activation)    (None, 14, 14, 512)  0           batch_normalization_1769[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1770 (Conv2D)            (None, 14, 14, 512)  2359808     activation_1634[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1770 (Batch (None, 14, 14, 512)  2048        conv2d_1770[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1635 (Activation)    (None, 14, 14, 512)  0           batch_normalization_1770[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1771 (Conv2D)            (None, 14, 14, 2048) 1050624     activation_1635[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1771 (Batch (None, 14, 14, 2048) 8192        conv2d_1771[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_530 (Add)                   (None, 14, 14, 2048) 0           batch_normalization_1771[0][0]   \n",
      "                                                                 activation_1633[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1636 (Activation)    (None, 14, 14, 2048) 0           add_530[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_32 (AveragePo (None, 2, 2, 2048)   0           activation_1636[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 2, 2, 1000)   2049000     average_pooling2d_32[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "identity_block = __import__('2-identity_block').identity_block\n",
    "projection_block = __import__('3-projection_block').projection_block\n",
    "\n",
    "\n",
    "\n",
    "def resnet50():\n",
    "    \"\"\" doc \"\"\"\n",
    "    MaxPooling2D = K.layers.MaxPooling2D\n",
    "    AveragePooling2D = K.layers.AveragePooling2D\n",
    "    Conv2D = K.layers.Conv2D\n",
    "    Dropout = K.layers.Dropout(rate=0.4)\n",
    "    Dense = K.layers.Dense\n",
    "    BatchNorm = K.layers.BatchNormalization\n",
    "    Activation = K.layers.Activation\n",
    "    Add = K.layers.Add\n",
    "    def layersConv(X, l, f, s=None, p='same'):\n",
    "        layer = Conv2D(l, f, s, padding=p,\n",
    "                       kernel_initializer='he_normal')(X)\n",
    "        layer = BatchNorm()(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "        return layer\n",
    "\n",
    "    X = K.Input(shape=(224, 224, 3))\n",
    "\n",
    "    layer = layersConv(X, 64, 7, 2)\n",
    "\n",
    "    layerMax = MaxPooling2D(3, 2, padding='same')(layer)\n",
    "\n",
    "    layer = projection_block(layer, [64, 64, 256], 1)\n",
    "    layer = identity_block(layer, [64, 64, 256])\n",
    "    layer = identity_block(layer, [64, 64, 256])\n",
    "\n",
    "    layer = projection_block(layer, [128, 128, 512])\n",
    "    layer = identity_block(layer, [128, 128, 512])\n",
    "    layer = identity_block(layer, [128, 128, 512])\n",
    "    layer = identity_block(layer, [128, 128, 512])\n",
    "\n",
    "    layer = projection_block(layer, [256, 256, 1024])\n",
    "    layer = identity_block(layer, [256, 256, 1024])\n",
    "    layer = identity_block(layer, [256, 256, 1024])\n",
    "    layer = identity_block(layer, [256, 256, 1024])\n",
    "    layer = identity_block(layer, [256, 256, 1024])\n",
    "    layer = identity_block(layer, [256, 256, 1024])\n",
    "\n",
    "    layer = projection_block(layer, [512, 512, 2048])\n",
    "    layer = identity_block(layer, [512, 512, 2048])\n",
    "    layer = identity_block(layer, [512, 512, 2048])\n",
    "\n",
    "    layerAVG = AveragePooling2D(1, 7)(layer)\n",
    "\n",
    "    Y = Dense(1000, activation=\"softmax\",\n",
    "              kernel_initializer='he_normal')(layerAVG)\n",
    "\n",
    "    model = K.Model(inputs=X, outputs=Y)\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = resnet50()\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_block(X, nb_filters, growth_rate, layers):\n",
    "    \"\"\" doc \"\"\"\n",
    "    \n",
    "    return\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X = K.Input(shape=(56, 56, 64))\n",
    "    Y, nb_filters = dense_block(X, 64, 32, 6)\n",
    "    model = K.models.Model(inputs=X, outputs=Y)\n",
    "    model.summary()\n",
    "    print(nb_filters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
