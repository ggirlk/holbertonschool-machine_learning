{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def uni_bleu(references, sentence):\n",
    "    \"\"\"\n",
    "    ******************************************************\n",
    "    ** Calculates the unigram BLEU score for a sentence **\n",
    "    ******************************************************\n",
    "    @references: is a list of reference translations\n",
    "                 each reference translation is a list\n",
    "                 of the words in the translation\n",
    "    @sentence: is a list containing the model proposed sentence\n",
    "    Returns:\n",
    "            the unigram BLEU score\n",
    "    \"\"\"\n",
    "    wordsDict = {}\n",
    "    for word in sentence:\n",
    "        wordsDict[word] = wordsDict.get(word, 0) + 1\n",
    "    maxs = {}\n",
    "    for reference in references:\n",
    "        ref = {}\n",
    "        for word in reference:\n",
    "            ref[word] = ref.get(word, 0) + 1\n",
    "        for word in ref:\n",
    "            maxs[word] = max(maxs.get(word, 0), ref[word])\n",
    "    in_ref = 0\n",
    "    for word in wordsDict:\n",
    "        in_ref += min(maxs.get(word, 0), wordsDict[word])\n",
    "    closest = np.argmin(np.abs([len(ref) - len(sentence)\n",
    "                                for ref in references]))\n",
    "    closest = len(references[closest])\n",
    "    if len(sentence) >= closest:\n",
    "        brevity = 1\n",
    "    else:\n",
    "        brevity = np.exp(1 - closest / len(sentence))\n",
    "    return brevity * in_ref / len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'there': 1, 'is': 1, 'a': 1, 'cat': 1, 'here': 1}\n",
      "0.6549846024623855\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "#uni_bleu = __import__('0-uni_bleu').uni_bleu\n",
    "\n",
    "references = [[\"the\", \"cat\", \"is\", \"on\", \"the\", \"mat\"], [\"there\", \"is\", \"a\", \"cat\", \"on\", \"the\", \"mat\"]]\n",
    "sentence = [\"there\", \"is\", \"a\", \"cat\", \"here\"]\n",
    "\n",
    "print(uni_bleu(references, sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def ngramify(wordsList, n):\n",
    "    \"\"\"\n",
    "    ***************************************************\n",
    "    *** Converts a words list of 1-grams to n-grams ***\n",
    "    ***************************************************\n",
    "    @wordsList: list of words of sentences\n",
    "    @n: number of grams\n",
    "    Return:\n",
    "            n-grams word list\n",
    "    \"\"\"\n",
    "    unlist = 0\n",
    "    if type(wordsList[0]) is not list:\n",
    "        wordsList = [wordsList]\n",
    "        unlist = 1\n",
    "    nWordsList = []\n",
    "    for line in wordsList:\n",
    "        new_line = []\n",
    "        for gram in range(len(line) - n + 1):\n",
    "            new_gram = \"\"\n",
    "            for i in range(n):\n",
    "                if i != 0:\n",
    "                    new_gram += \" \"\n",
    "                new_gram += line[gram + i]\n",
    "            new_line.append(new_gram)\n",
    "        nWordsList.append(new_line)\n",
    "    if unlist:\n",
    "        return nWordsList[0]\n",
    "    return nWordsList\n",
    "\n",
    "\n",
    "def ngram_bleu(references, sentence, n):\n",
    "    \"\"\"\n",
    "    ******************************************************\n",
    "    *** calculates the n-gram BLEU score for a sentence **\n",
    "    ******************************************************\n",
    "    @references: is a list of reference translations\n",
    "                 each reference translation is a list\n",
    "                 of the words in the translation\n",
    "    @sentence: is a list containing the model proposed sentence\n",
    "    @n: is the size of the n-gram to use for evaluation\n",
    "    Returns:\n",
    "            the unigram BLEU score\n",
    "    \"\"\"\n",
    "    references = ngramify(references, n)\n",
    "    sentence = ngramify(sentence, n)\n",
    "    wordsDict = {}\n",
    "    for gram in sentence:\n",
    "        wordsDict[gram] = wordsDict.get(gram, 0) + 1\n",
    "    max_dict = {}\n",
    "    for reference in references:\n",
    "        ref = {}\n",
    "        for gram in reference:\n",
    "            ref[gram] = ref.get(gram, 0) + 1\n",
    "        for gram in ref:\n",
    "            max_dict[gram] = max(max_dict.get(gram, 0), ref[gram])\n",
    "    in_ref = 0\n",
    "    for gram in wordsDict:\n",
    "        in_ref += min(max_dict.get(gram, 0), wordsDict[gram])\n",
    "    closest = np.argmin(np.abs([len(ref) - len(sentence)\n",
    "                        for ref in references]))\n",
    "    closest = len(references[closest])\n",
    "    if len(sentence) >= closest:\n",
    "        brevity = 1\n",
    "    else:\n",
    "        brevity = np.exp(1 - (closest + n - 1) / (len(sentence) + n - 1))\n",
    "    return brevity * in_ref / len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6140480648084865\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "#ngram_bleu = __import__('1-ngram_bleu').ngram_bleu\n",
    "\n",
    "references = [[\"the\", \"cat\", \"is\", \"on\", \"the\", \"mat\"], [\"there\", \"is\", \"a\", \"cat\", \"on\", \"the\", \"mat\"]]\n",
    "sentence = [\"there\", \"is\", \"a\", \"cat\", \"here\"]\n",
    "\n",
    "print(ngram_bleu(references, sentence, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngramify(wordsList, n):\n",
    "    \"\"\"\n",
    "    ***************************************************\n",
    "    *** Converts a words list of 1-grams to n-grams ***\n",
    "    ***************************************************\n",
    "    @wordsList: list of words of sentences\n",
    "    @n: number of grams\n",
    "    Return:\n",
    "            n-grams word list\n",
    "    \"\"\"\n",
    "    unlist = 0\n",
    "    if type(wordsList[0]) is not list:\n",
    "        wordsList = [wordsList]\n",
    "        unlist = 1\n",
    "    nWordsList = []\n",
    "    for line in wordsList:\n",
    "        new_line = []\n",
    "        for gram in range(len(line) - n + 1):\n",
    "            new_gram = \"\"\n",
    "            for i in range(n):\n",
    "                if i != 0:\n",
    "                    new_gram += \" \"\n",
    "                new_gram += line[gram + i]\n",
    "            new_line.append(new_gram)\n",
    "        nWordsList.append(new_line)\n",
    "    if unlist:\n",
    "        return nWordsList[0]\n",
    "    return nWordsList\n",
    "\n",
    "\n",
    "def ngram_modscore(references, sentence, n):\n",
    "    \"\"\"\n",
    "    **************************************************\n",
    "    ********** Calculate unigram bleu score **********\n",
    "    **************************************************\n",
    "    @references: is a list of reference translations\n",
    "                each reference translation is a list\n",
    "                of the words in the translation\n",
    "    @sentence: is a list containing the model proposed sentence\n",
    "    @n: is the size of the largest n-gram to use for evaluation\n",
    "    *** All n-gram scores should be weighted evenly\n",
    "    Returns:\n",
    "            the unigram n-gram BLEU score\n",
    "    \"\"\"\n",
    "    references = ngramify(references, n)\n",
    "    sentence = ngramify(sentence, n)\n",
    "    sent_dict = {}\n",
    "    for gram in sentence:\n",
    "        sent_dict[gram] = sent_dict.get(gram, 0) + 1\n",
    "    max_dict = {}\n",
    "    for reference in references:\n",
    "        this_ref = {}\n",
    "        for gram in reference:\n",
    "            this_ref[gram] = this_ref.get(gram, 0) + 1\n",
    "        for gram in this_ref:\n",
    "            max_dict[gram] = max(max_dict.get(gram, 0), this_ref[gram])\n",
    "    in_ref = 0\n",
    "    for gram in sent_dict:\n",
    "        in_ref += min(max_dict.get(gram, 0), sent_dict[gram])\n",
    "    return  np.log(in_ref / len(sentence))\n",
    "\n",
    "def cumulative_bleu(references, sentence, n):\n",
    "    \"\"\"\n",
    "    ***************************************************\n",
    "    *** calculates the cumulative n-gram BLEU score ***\n",
    "    ***************************************************\n",
    "    @references: is a list of reference translations\n",
    "                each reference translation is a list\n",
    "                of the words in the translation\n",
    "    @sentence: is a list containing the model proposed sentence\n",
    "    @n: is the size of the largest n-gram to use for evaluation\n",
    "    *** All n-gram scores should be weighted evenly\n",
    "    Returns:\n",
    "            the cumulative n-gram BLEU score\n",
    "\n",
    "    \"\"\"\n",
    "    weight = 1 / n\n",
    "    scores = [ngram_modscore(references, sentence, i) * weight\n",
    "              for i in range(1, n + 1)]\n",
    "    closest = np.argmin(np.abs([len(ref) - len(sentence)\n",
    "                        for ref in references]))\n",
    "    closest = len(references[closest])\n",
    "    if len(sentence) >= closest:\n",
    "        brevity = 1\n",
    "    else:\n",
    "        brevity = np.exp(1 - closest / len(sentence))\n",
    "    return brevity * np.exp(sum(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5475182535069453\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "#cumulative_bleu = __import__('1-cumulative_bleu').cumulative_bleu\n",
    "\n",
    "references = [[\"the\", \"cat\", \"is\", \"on\", \"the\", \"mat\"], [\"there\", \"is\", \"a\", \"cat\", \"on\", \"the\", \"mat\"]]\n",
    "sentence = [\"there\", \"is\", \"a\", \"cat\", \"here\"]\n",
    "\n",
    "print(cumulative_bleu(references, sentence, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
