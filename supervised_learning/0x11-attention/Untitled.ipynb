{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch 6-multihead_attention.py\n",
    "!chmod +x *.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RNNEncoder(tf.keras.layers.Layer):\n",
    "    \"\"\" encoder for machine translation \"\"\"\n",
    "\n",
    "    def __init__(self, vocab, embedding, units, batch):\n",
    "        \"\"\"\n",
    "        *********************************************\n",
    "        *****************Constructor*****************\n",
    "        *********************************************\n",
    "        @vocab: is an integer representing the size\n",
    "                of the input vocabulary\n",
    "        @embedding: is an integer representing the\n",
    "                    dimensionality of the embedding vector\n",
    "        @units: is an integer representing the number\n",
    "                of hidden units in the RNN cell\n",
    "        @batch: is an integer representing the batch size\n",
    "        \"\"\"\n",
    "        super(RNNEncoder, self).__init__()\n",
    "        self.vocab = vocab\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab, embedding)\n",
    "        self.units = units\n",
    "        self.batch = batch\n",
    "        \n",
    "        self.gru = tf.keras.layers.GRU(\n",
    "                    units,\n",
    "                    kernel_initializer=\"glorot_uniform\",\n",
    "                    recurrent_initializer=\"glorot_uniform\",\n",
    "                    return_sequences=True,\n",
    "                    return_state=True\n",
    "                    )\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        \"\"\"\n",
    "        nitializes the hidden states for\n",
    "        the RNN cell to a tensor of zeros\n",
    "        \"\"\"\n",
    "        return tf.zeros((self.batch, self.units))\n",
    "\n",
    "    def call(self, x, initial):\n",
    "        \"\"\"\n",
    "        calls the encoders layers\n",
    "        \"\"\"\n",
    "        embading = self.embedding(x)\n",
    "        outputs = self.gru(embading, initial_state=initial)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "256\n",
      "<class 'tensorflow.python.keras.layers.embeddings.Embedding'>\n",
      "<class 'tensorflow.python.keras.layers.recurrent.GRU'>\n",
      "Tensor(\"zeros_14:0\", shape=(32, 256), dtype=float32)\n",
      "Tensor(\"rnn_encoder_5/gru_14/transpose_1:0\", shape=(32, 10, 256), dtype=float32)\n",
      "Tensor(\"rnn_encoder_5/gru_14/while/Exit_3:0\", shape=(32, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#RNNEncoder = __import__('0-rnn_encoder').RNNEncoder\n",
    "\n",
    "encoder = RNNEncoder(1024, 128, 256, 32)\n",
    "print(encoder.batch)\n",
    "print(encoder.units)\n",
    "print(type(encoder.embedding))\n",
    "print(type(encoder.gru))\n",
    "\n",
    "initial = encoder.initialize_hidden_state()\n",
    "print(initial)\n",
    "x = tf.convert_to_tensor(np.random.choice(1024, 320).reshape((32, 10)))\n",
    "outputs, hidden = encoder(x, initial)\n",
    "print(outputs)\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class SelfAttention(tf.keras.layers.Layer):\n",
    "    \"\"\" calculate the attention for machine translation \"\"\"\n",
    "\n",
    "    def __init__(self, units):\n",
    "        \"\"\"\n",
    "        *********************************************\n",
    "        *****************Constructor*****************\n",
    "        *********************************************\n",
    "        @units: is an integer representing the number\n",
    "                of hidden units in the alignment model\n",
    "        \"\"\"\n",
    "        super(SelfAttention, self).__init__()\n",
    "        # a Dense layer with units units, to be applied to\n",
    "        # the previous decoder hidden state\n",
    "        self.W = tf.keras.layers.Dense(units)\n",
    "        # a Dense layer with units units, to be applied to\n",
    "        # the encoder hidden states\n",
    "        self.U = tf.keras.layers.Dense(units)\n",
    "        # a Dense layer with 1 units, to be applied to the\n",
    "        # tanh of the sum of the outputs of W and U\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, s_prev, hidden_states):\n",
    "        \"\"\"\n",
    "        ************************************************************\n",
    "        *****************calls the attention layers*****************\n",
    "        ************************************************************\n",
    "        \n",
    "        @s_prev: is a tensor of shape (batch, units) containing the\n",
    "                 previous decoder hidden state\n",
    "        @hidden_states: is a tensor of shape (batch, input_seq_len,\n",
    "                        units)containing the outputs of the encoder\n",
    "        Returns:\n",
    "                context: is a tensor of shape (batch, units) that\n",
    "                         contains the context vector for the decoder\n",
    "                weights: is a tensor of shape (batch, input_seq_len, 1)\n",
    "                         that contains the attention weights\n",
    "        \"\"\"\n",
    "        s_prev = tf.expand_dims(s_prev, 1)\n",
    "        e = self.V(tf.nn.tanh(self.W(s_prev) + self.U(hidden_states)))\n",
    "        weights = tf.nn.softmax(e, axis=1)\n",
    "        context = weights * hidden_states\n",
    "        context = tf.reduce_sum(context, axis=1)\n",
    "        return context, weights\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.core.Dense object at 0x7f5a0ffc6ba8>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x7f5a0ffc69e8>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x7f5a0f267390>\n",
      "Tensor(\"self_attention_1/Sum:0\", shape=(32, 256), dtype=float32)\n",
      "Tensor(\"self_attention_1/transpose_1:0\", shape=(32, 10, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#SelfAttention = __import__('1-self_attention').SelfAttention\n",
    "\n",
    "attention = SelfAttention(256)\n",
    "print(attention.W)\n",
    "print(attention.U)\n",
    "print(attention.V)\n",
    "s_prev = tf.convert_to_tensor(np.random.uniform(size=(32, 256)), preferred_dtype='float32')\n",
    "hidden_states = tf.convert_to_tensor(np.random.uniform(size=(32, 10, 256)), preferred_dtype='float32')\n",
    "context, weights = attention(s_prev, hidden_states)\n",
    "print(context)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\" RNN Decoder \"\"\"\n",
    "import tensorflow as tf\n",
    "\n",
    "SelfAttention = __import__('1-self_attention').SelfAttention\n",
    "\n",
    "\n",
    "class RNNDecoder(tf.keras.layers.Layer):\n",
    "    \"\"\" decode for machine translation \"\"\"\n",
    "\n",
    "    def __init__(self, vocab, embedding, units, batch):\n",
    "        \"\"\"\n",
    "        *********************************************\n",
    "        *****************Constructor*****************\n",
    "        *********************************************\n",
    "        @vocab: is an integer representing the size of\n",
    "                the output vocabulary\n",
    "        @embedding: is an integer representing the\n",
    "                    dimensionality of the embedding vector\n",
    "        @units: is an integer representing the number\n",
    "                of hidden units in the RNN cell\n",
    "        @batch: is an integer representing the batch size\n",
    "        \"\"\"\n",
    "        super(RNNDecoder, self).__init__()\n",
    "        # keras Embedding layer that converts words from\n",
    "        # the vocabulary into an embedding vector\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab, embedding)\n",
    "        # keras GRU layer with units units\n",
    "        # return both the full sequence of output\n",
    "        # as well as the last hidden state\n",
    "        self.gru = tf.keras.layers.GRU(units, return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        # Dense layer with vocab units\n",
    "        self.F = tf.keras.layers.Dense(vocab)\n",
    "\n",
    "    def call(self, x, s_prev, hidden_states):\n",
    "        \"\"\"\n",
    "        **********************************************************\n",
    "        *****************calls the decoder layers*****************\n",
    "        **********************************************************\n",
    "        @x: is a tensor of shape (batch, 1) containing the previous\n",
    "            word in the target sequence as an index of the target vocabulary\n",
    "        @s_prev: is a tensor of shape (batch, units) containing the\n",
    "                 previous decoder hidden state\n",
    "        @hidden_states: is a tensor of shape (batch, input_seq_len,\n",
    "                        units)containing the outputs of the encoder\n",
    "        Returns:\n",
    "                y: is a tensor of shape (batch, vocab) containing\n",
    "                   the output word as a one hot vector in the target vocabulary\n",
    "                s: is a tensor of shape (batch, units) containing\n",
    "                   the new decoder hidden state\n",
    "        \"\"\"\n",
    "        attention = SelfAttention(s_prev.shape[1])\n",
    "        context, weights = attention(s_prev, hidden_states)\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context, 1), x], -1)\n",
    "        output, s = self.gru(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        y = self.F(output)\n",
    "        return y, s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.embeddings.Embedding object at 0x7fced955c860>\n",
      "<tensorflow.python.keras.layers.recurrent.GRU object at 0x7fced955cb00>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x7fced955ce80>\n",
      "Tensor(\"rnn_decoder_6/dense_24/BiasAdd:0\", shape=(32, 2048), dtype=float32)\n",
      "Tensor(\"rnn_decoder_6/gru_6/while/Exit_3:0\", shape=(32, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#RNNDecoder = __import__('2-rnn_decoder').RNNDecoder\n",
    "\n",
    "decoder = RNNDecoder(2048, 128, 256, 32)\n",
    "print(decoder.embedding)\n",
    "print(decoder.gru)\n",
    "print(decoder.F)\n",
    "x = tf.convert_to_tensor(np.random.choice(2048, 32).reshape((32, 1)))\n",
    "s_prev = tf.convert_to_tensor(np.random.uniform(size=(32, 256)).astype('float32'))\n",
    "hidden_states = tf.convert_to_tensor(np.random.uniform(size=(32, 10, 256)).astype('float32'))\n",
    "y, s = decoder(x, s_prev, hidden_states)\n",
    "print(y)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.keras.layers.embeddings.Embedding'> 2048 128\n",
      "<class 'tensorflow.python.keras.layers.recurrent.GRU'> 256\n",
      "<class 'tensorflow.python.keras.layers.core.Dense'> 2048\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#RNNDecoder = __import__('2-rnn_decoder').RNNDecoder\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "decoder = RNNDecoder(2048, 128, 256, 32)\n",
    "print(type(decoder.embedding), decoder.embedding.input_dim, decoder.embedding.output_dim)\n",
    "print(type(decoder.gru), decoder.gru.units)\n",
    "print(type(decoder.F), decoder.F.units)\n",
    "\n",
    "with open('1-test', 'w+') as f:\n",
    "    x = tf.convert_to_tensor(np.random.choice(2048, 32).reshape((32, 1)))\n",
    "    s_prev = tf.convert_to_tensor(np.random.uniform(size=(32, 256)).astype('float32'))\n",
    "    hidden_states = tf.convert_to_tensor(np.random.uniform(size=(32, 10, 256)).astype('float32'))\n",
    "    y, s = decoder(x, s_prev, hidden_states)\n",
    "    Y = tf.keras.backend.eval(y)\n",
    "    S = tf.keras.backend.eval(s)\n",
    "    f.write(str(Y.shape) + '\\n' + np.array2string(Y, precision=5) + '\\n')\n",
    "    f.write(str(S.shape) + '\\n' + np.array2string(S, precision=5) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\" Positional Encoding \"\"\"\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def positional_encoding(max_seq_len, dm):\n",
    "    \"\"\"\n",
    "    calculates the positional encoding for a transformer\n",
    "    @max_seq_len: is an integer representing the maximum\n",
    "                  sequence length\n",
    "    @dm: is the model depth\n",
    "    Returns:\n",
    "            a numpy.ndarray of shape (max_seq_len, dm)\n",
    "            containing the positional encoding vectors\n",
    "    \"\"\"\n",
    "    pEncoding = np.ndarray((max_seq_len, dm))\n",
    "    for i in range(max_seq_len):\n",
    "        for j in range(dm):\n",
    "            if j % 2:\n",
    "                pEncoding[i][j] = np.cos(i / np.power(10000, (j - 1) / dm))\n",
    "            else:\n",
    "                pEncoding[i][j] = np.sin(i / np.power(10000, j / dm))\n",
    "    return pEncoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 512)\n",
      "[[ 0.00000000e+00  1.00000000e+00  0.00000000e+00 ...  1.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 8.41470985e-01  5.40302306e-01  8.21856190e-01 ...  9.99999994e-01\n",
      "   1.03663293e-04  9.99999995e-01]\n",
      " [ 9.09297427e-01 -4.16146837e-01  9.36414739e-01 ...  9.99999977e-01\n",
      "   2.07326584e-04  9.99999979e-01]\n",
      " ...\n",
      " [ 9.56375928e-01 -2.92138809e-01  7.91416314e-01 ...  9.99995791e-01\n",
      "   2.79890525e-03  9.99996083e-01]\n",
      " [ 2.70905788e-01 -9.62605866e-01  9.53248145e-01 ...  9.99995473e-01\n",
      "   2.90256812e-03  9.99995788e-01]\n",
      " [-6.63633884e-01 -7.48057530e-01  2.94705106e-01 ...  9.99995144e-01\n",
      "   3.00623096e-03  9.99995481e-01]]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import numpy as np\n",
    "#positional_encoding = __import__('4-positional_encoding').positional_encoding\n",
    "\n",
    "PE = positional_encoding(30, 512)\n",
    "print(PE.shape)\n",
    "print(PE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\" Scaled Dot Product Attention \"\"\"\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def sdp_attention(Q, K, V, mask=None):\n",
    "    \"\"\"\n",
    "    Calculate scaled dot product attention\n",
    "    @Q: is a tensor with its last two dimensions\n",
    "        as (..., seq_len_q, dk) containing the query matrix\n",
    "    @K: is a tensor with its last two dimensions\n",
    "        as (..., seq_len_v, dk) containing the key matrix\n",
    "    @V: is a tensor with its last two dimensions\n",
    "        as (..., seq_len_v, dv) containing the value matrix\n",
    "    @mask: is a tensor that can be broadcast into\n",
    "           (..., seq_len_q, seq_len_v) containing the optional\n",
    "           mask, or defaulted to None\n",
    "    *** If mask is not None, multiply -1e9 to the mask and add\n",
    "        it to the scaled matrix multiplication\n",
    "    *** The preceding dimensions of Q, K, and V are the same\n",
    "    Returns:\n",
    "            output: a tensor with its last two dimensions as\n",
    "                    (..., seq_len_q, dv) containing the scaled dot\n",
    "                    product attention\n",
    "            weights: a tensor with its last two dimensions as\n",
    "                     (..., seq_len_q, seq_len_v) containing the\n",
    "                     attention weights\n",
    "    \"\"\"\n",
    "    sqrt = tf.math.sqrt(tf.cast(tf.shape(K)[-1], float))\n",
    "    scaled = tf.matmul(Q, K, transpose_b=True) / sqrt\n",
    "    if mask is not None:\n",
    "        scaled = mask * -1e9 + scaled\n",
    "    scaled = tf.nn.softmax(scaled, axis=-1)\n",
    "    return tf.matmul(scaled, V), scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MatMul_1:0\", shape=(50, 10, 512), dtype=float32)\n",
      "Tensor(\"Softmax:0\", shape=(50, 10, 15), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#sdp_attention = __import__('5-sdp_attention').sdp_attention\n",
    "\n",
    "np.random.seed(0)\n",
    "Q = tf.convert_to_tensor(np.random.uniform(size=(50, 10, 256)).astype('float32'))\n",
    "K = tf.convert_to_tensor(np.random.uniform(size=(50, 15, 256)).astype('float32'))\n",
    "V = tf.convert_to_tensor(np.random.uniform(size=(50, 15, 512)).astype('float32'))\n",
    "output, weights = sdp_attention(Q, K, V)\n",
    "print(output)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\" Multi Head Attention \"\"\"\n",
    "import tensorflow as tf\n",
    "\n",
    "#sdp_attention = __import__('5-sdp_attention').sdp_attention\n",
    "\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \"\"\" perform multi head attention \"\"\"\n",
    "\n",
    "    def __init__(self, dm, h):\n",
    "        \"\"\"\n",
    "        *********************************************\n",
    "        *****************Constructor*****************\n",
    "        *********************************************\n",
    "        @dm: is an integer representing the dimensionality\n",
    "             of the model (divisible by h)\n",
    "        @h: is an integer representing the number of heads\n",
    "        \"\"\"\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        # the number of heads\n",
    "        self.h = h\n",
    "        # the dimensionality of the model\n",
    "        self.dm = dm\n",
    "        # the depth of each attention head\n",
    "        self.depth = dm // h\n",
    "        # a Dense layer with dm units, used to generate the query matrix\n",
    "        self.Wq = tf.keras.layers.Dense(dm)\n",
    "        # a Dense layer with dm units, used to generate the key matrix\n",
    "        self.Wk = tf.keras.layers.Dense(dm)\n",
    "        # a Dense layer with dm units, used to generate the value matrix\n",
    "        self.Wv = tf.keras.layers.Dense(dm)\n",
    "        # a Dense layer with dm units, used to generate the attention output\n",
    "        self.linear = tf.keras.layers.Dense(dm)\n",
    "\n",
    "    def call(self, Q, K, V, mask):\n",
    "        \"\"\"\n",
    "        ************************************************\n",
    "        ****************Keras layer call****************\n",
    "        ************************************************\n",
    "        @Q: is a tensor of shape (batch, seq_len_q, dk)\n",
    "            containing the input to generate the query matrix\n",
    "        @K: is a tensor of shape (batch, seq_len_v, dk)\n",
    "            containing the input to generate the key matrix\n",
    "        @V: is a tensor of shape (batch, seq_len_v, dv)\n",
    "            containing the input to generate the value matrix\n",
    "        @mask: is always None\n",
    "        Returns:\n",
    "                output: a tensor with its last two dimensions as\n",
    "                        (..., seq_len_q, dm) containing the scaled\n",
    "                        dot product attention\n",
    "                weights: a tensor with its last three dimensions as\n",
    "                        (..., h, seq_len_q, seq_len_v) containing\n",
    "                        the attention weights\n",
    "        \"\"\"\n",
    "        batches = tf.shape(Q)[0]\n",
    "        Q = self.Wq(Q)\n",
    "        K = self.Wk(K)\n",
    "        V = self.Wv(V)\n",
    "\n",
    "        def split_heads(x, batch_size):\n",
    "            x = tf.reshape(x, (batch_size, -1, self.h, self.depth))\n",
    "            return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        Q = split_heads(Q, batches)\n",
    "        K = split_heads(K, batches)\n",
    "        V = split_heads(V, batches)\n",
    "        output, weights = sdp_attention(Q, K, V, mask)\n",
    "        output = tf.transpose(output, perm=[0, 2, 1, 3])\n",
    "        output = tf.reshape(output, [batches, -1, self.dm])\n",
    "        return self.linear(output), weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "8\n",
      "64\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x7fcec13522b0>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x7fcec00cd240>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x7fcec00cd7f0>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x7fcec00cdbe0>\n",
      "Tensor(\"multi_head_attention_1/dense_47/BiasAdd:0\", shape=(50, 15, 512), dtype=float32)\n",
      "Tensor(\"multi_head_attention_1/Softmax:0\", shape=(50, 8, 15, 15), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#MultiHeadAttention = __import__('6-multihead_attention').MultiHeadAttention\n",
    "\n",
    "mha = MultiHeadAttention(512, 8)\n",
    "print(mha.dm)\n",
    "print(mha.h)\n",
    "print(mha.depth)\n",
    "print(mha.Wq)\n",
    "print(mha.Wk)\n",
    "print(mha.Wv)\n",
    "print(mha.linear)\n",
    "Q = tf.convert_to_tensor(np.random.uniform(size=(50, 15, 256)).astype('float32'))\n",
    "K = tf.convert_to_tensor(np.random.uniform(size=(50, 15, 256)).astype('float32'))\n",
    "V = tf.convert_to_tensor(np.random.uniform(size=(50, 15, 256)).astype('float32'))\n",
    "output, weights = mha(Q, K, V, None)\n",
    "print(output)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
